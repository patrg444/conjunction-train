{
  "branched_regularization_sync_aug_tcn_large_fixed_v2_no_maxnorm_v20250327_182630": {
    "log_file": "emotion_training_logs/training_branched_regularization_sync_aug_tcn_large_fixed_v2_no_maxnorm_v20250327_182630.log",
    "summary": {
      "epochs_completed": 102,
      "latest_val_accuracy": 0.8086,
      "best_val_accuracy": 0.8126,
      "best_epoch": 101,
      "recent_trend": -0.0008499999999999947
    },
    "metrics": {
      "epoch": [
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12,
        13,
        14,
        15,
        16,
        17,
        18,
        19,
        20,
        21,
        22,
        23,
        24,
        25,
        26,
        27,
        28,
        29,
        30,
        31,
        32,
        33,
        34,
        35,
        36,
        37,
        38,
        39,
        40,
        41,
        42,
        43,
        44,
        45,
        46,
        47,
        48,
        49,
        50,
        51,
        52,
        53,
        54,
        55,
        56,
        57,
        58,
        59,
        60,
        61,
        62,
        63,
        64,
        65,
        66,
        67,
        68,
        69,
        70,
        71,
        72,
        73,
        74,
        75,
        76,
        77,
        78,
        79,
        80,
        81,
        82,
        83,
        84,
        85,
        86,
        87,
        88,
        89,
        90,
        91,
        92,
        93,
        94,
        95,
        96,
        97,
        98,
        99,
        100,
        101,
        102
      ],
      "val_accuracy": [
        0.3299,
        0.3713,
        0.4144,
        0.4667,
        0.5557,
        0.5764,
        0.5408,
        0.5931,
        0.608,
        0.5925,
        0.5557,
        0.6086,
        0.5385,
        0.5845,
        0.6063,
        0.5897,
        0.5695,
        0.6362,
        0.6224,
        0.6534,
        0.6661,
        0.6483,
        0.6736,
        0.6856,
        0.7006,
        0.6672,
        0.6902,
        0.7023,
        0.6644,
        0.7121,
        0.7034,
        0.7069,
        0.723,
        0.7138,
        0.6885,
        0.6966,
        0.7,
        0.7109,
        0.7218,
        0.7201,
        0.7207,
        0.7408,
        0.7523,
        0.7276,
        0.7517,
        0.7546,
        0.769,
        0.7241,
        0.7477,
        0.7374,
        0.7534,
        0.7448,
        0.7523,
        0.7397,
        0.7437,
        0.7511,
        0.7678,
        0.7684,
        0.7632,
        0.7506,
        0.7816,
        0.7741,
        0.7655,
        0.773,
        0.7437,
        0.781,
        0.7684,
        0.7782,
        0.7764,
        0.7885,
        0.7874,
        0.7897,
        0.7828,
        0.7667,
        0.7603,
        0.7805,
        0.7839,
        0.8034,
        0.7925,
        0.7799,
        0.7701,
        0.792,
        0.7931,
        0.7885,
        0.7862,
        0.8017,
        0.7902,
        0.7931,
        0.7908,
        0.8,
        0.7931,
        0.8063,
        0.8,
        0.7851,
        0.8115,
        0.7994,
        0.8046,
        0.8011,
        0.7977,
        0.8103,
        0.8126,
        0.8086
      ]
    }
  },
  "branched_lstm_conv1d_20250328_224236": {
    "log_file": "emotion_training_logs/training_branched_lstm_conv1d_20250328_224236.log",
    "summary": {
      "epochs_completed": 31,
      "latest_val_accuracy": 0.7782,
      "best_val_accuracy": 0.8132,
      "best_epoch": 1,
      "recent_trend": 0.003449999999999911
    },
    "metrics": {
      "epoch": [
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12,
        13,
        14,
        15,
        16,
        17,
        18,
        19,
        20,
        21,
        22,
        23,
        24,
        25,
        26,
        27,
        28,
        29,
        30,
        31
      ],
      "val_accuracy": [
        0.8132,
        0.8115,
        0.8034,
        0.7989,
        0.7943,
        0.7897,
        0.792,
        0.7615,
        0.7615,
        0.7569,
        0.7684,
        0.7557,
        0.7592,
        0.7701,
        0.7787,
        0.7483,
        0.7713,
        0.7764,
        0.7575,
        0.7822,
        0.7782,
        0.7569,
        0.7695,
        0.7718,
        0.7701,
        0.7667,
        0.7851,
        0.7816,
        0.7713,
        0.7741,
        0.7782
      ]
    }
  },
  "precomputed_cnn_lstm_20250404_165825": {
    "log_file": "emotion_training_logs/training_precomputed_cnn_lstm_20250404_165825.log",
    "summary": {
      "epochs_completed": 175,
      "latest_val_accuracy": 0.8322,
      "best_val_accuracy": 0.8362,
      "best_epoch": 168,
      "recent_trend": 0.0003000000000000106
    },
    "metrics": {
      "epoch": [
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12,
        13,
        14,
        15,
        16,
        17,
        18,
        19,
        20,
        21,
        22,
        23,
        24,
        25,
        26,
        27,
        28,
        29,
        30,
        31,
        32,
        33,
        34,
        35,
        36,
        37,
        38,
        39,
        40,
        41,
        42,
        43,
        44,
        45,
        46,
        47,
        48,
        49,
        50,
        51,
        52,
        53,
        54,
        55,
        56,
        57,
        58,
        59,
        60,
        61,
        62,
        63,
        64,
        65,
        66,
        67,
        68,
        69,
        70,
        71,
        72,
        73,
        74,
        75,
        76,
        77,
        78,
        79,
        80,
        81,
        82,
        83,
        84,
        85,
        86,
        87,
        88,
        89,
        90,
        91,
        92,
        93,
        94,
        95,
        96,
        97,
        98,
        99,
        100,
        101,
        102,
        103,
        104,
        105,
        106,
        107,
        108,
        109,
        110,
        111,
        112,
        113,
        114,
        115,
        116,
        117,
        118,
        119,
        120,
        121,
        122,
        123,
        124,
        125,
        126,
        127,
        128,
        129,
        130,
        131,
        132,
        133,
        134,
        135,
        136,
        137,
        138,
        139,
        140,
        141,
        142,
        143,
        144,
        145,
        146,
        147,
        148,
        149,
        150,
        151,
        152,
        153,
        154,
        155,
        156,
        157,
        158,
        159,
        160,
        161,
        162,
        163,
        164,
        165,
        166,
        167,
        168,
        169,
        170,
        171,
        172,
        173,
        174,
        175
      ],
      "val_accuracy": [
        0.1695,
        0.1707,
        0.1741,
        0.2029,
        0.2701,
        0.3132,
        0.4282,
        0.446,
        0.4592,
        0.4511,
        0.5126,
        0.5546,
        0.5626,
        0.6052,
        0.5983,
        0.6149,
        0.6195,
        0.6379,
        0.6494,
        0.6356,
        0.669,
        0.6138,
        0.6741,
        0.7006,
        0.6299,
        0.6914,
        0.7034,
        0.6109,
        0.6948,
        0.7184,
        0.6868,
        0.7092,
        0.7034,
        0.7057,
        0.7155,
        0.7144,
        0.7385,
        0.7236,
        0.7448,
        0.7345,
        0.7529,
        0.7029,
        0.7626,
        0.7598,
        0.7448,
        0.7351,
        0.742,
        0.7236,
        0.7374,
        0.7489,
        0.7586,
        0.7615,
        0.7172,
        0.7282,
        0.7557,
        0.7483,
        0.754,
        0.7914,
        0.769,
        0.7879,
        0.7517,
        0.7649,
        0.7799,
        0.769,
        0.7489,
        0.7736,
        0.7799,
        0.7753,
        0.7759,
        0.7632,
        0.7874,
        0.7764,
        0.7747,
        0.7793,
        0.7828,
        0.7937,
        0.7868,
        0.7741,
        0.7948,
        0.7931,
        0.7971,
        0.7713,
        0.8069,
        0.792,
        0.7822,
        0.7874,
        0.8017,
        0.7925,
        0.7891,
        0.7885,
        0.7983,
        0.7948,
        0.7672,
        0.8086,
        0.8109,
        0.8075,
        0.7816,
        0.7977,
        0.8046,
        0.8075,
        0.804,
        0.8057,
        0.7983,
        0.8149,
        0.8224,
        0.8149,
        0.8115,
        0.8098,
        0.8172,
        0.8034,
        0.8098,
        0.8224,
        0.8161,
        0.8086,
        0.8086,
        0.8092,
        0.8006,
        0.8293,
        0.8046,
        0.8253,
        0.8167,
        0.8184,
        0.8155,
        0.8103,
        0.8328,
        0.8282,
        0.831,
        0.8103,
        0.8155,
        0.8247,
        0.8167,
        0.8144,
        0.8322,
        0.8264,
        0.8247,
        0.8195,
        0.8178,
        0.8144,
        0.8299,
        0.8178,
        0.8253,
        0.8328,
        0.8155,
        0.8333,
        0.8218,
        0.8213,
        0.8339,
        0.827,
        0.831,
        0.8224,
        0.8305,
        0.8299,
        0.8264,
        0.8322,
        0.8253,
        0.8264,
        0.8299,
        0.8287,
        0.8293,
        0.8299,
        0.8282,
        0.8316,
        0.8299,
        0.8333,
        0.8351,
        0.8316,
        0.8351,
        0.8362,
        0.8345,
        0.8339,
        0.8305,
        0.8351,
        0.8316,
        0.8322,
        0.8322
      ]
    }
  },
  "branched_lstm_conv1d_20250328_193633": {
    "log_file": "emotion_training_logs/training_branched_lstm_conv1d_20250328_193633.log",
    "summary": {
      "epochs_completed": 15,
      "latest_val_accuracy": 0.692,
      "best_val_accuracy": 0.692,
      "best_epoch": 15,
      "recent_trend": 0.013550000000000038
    },
    "metrics": {
      "epoch": [
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12,
        13,
        14,
        15
      ],
      "val_accuracy": [
        0.2862,
        0.3954,
        0.4207,
        0.4954,
        0.5437,
        0.5851,
        0.6115,
        0.6517,
        0.6356,
        0.6425,
        0.6443,
        0.6437,
        0.6649,
        0.6759,
        0.692
      ]
    }
  },
  "branched_regularization_sync_aug_tcn_large_fixed_v2_v20250327_203326": {
    "log_file": "emotion_training_logs/training_branched_regularization_sync_aug_tcn_large_fixed_v2_v20250327_203326.log",
    "summary": {
      "epochs_completed": 125,
      "latest_val_accuracy": 0.8293,
      "best_val_accuracy": 0.8293,
      "best_epoch": 125,
      "recent_trend": 0.0008499999999999097
    },
    "metrics": {
      "epoch": [
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12,
        13,
        14,
        15,
        16,
        17,
        18,
        19,
        20,
        21,
        22,
        23,
        24,
        25,
        26,
        27,
        28,
        29,
        30,
        31,
        32,
        33,
        34,
        35,
        36,
        37,
        38,
        39,
        40,
        41,
        42,
        43,
        44,
        45,
        46,
        47,
        48,
        49,
        50,
        51,
        52,
        53,
        54,
        55,
        56,
        57,
        58,
        59,
        60,
        61,
        62,
        63,
        64,
        65,
        66,
        67,
        68,
        69,
        70,
        71,
        72,
        73,
        74,
        75,
        76,
        77,
        78,
        79,
        80,
        81,
        82,
        83,
        84,
        85,
        86,
        87,
        88,
        89,
        90,
        91,
        92,
        93,
        94,
        95,
        96,
        97,
        98,
        99,
        100,
        101,
        102,
        103,
        104,
        105,
        106,
        107,
        108,
        109,
        110,
        111,
        112,
        113,
        114,
        115,
        116,
        117,
        118,
        119,
        120,
        121,
        122,
        123,
        124,
        125
      ],
      "val_accuracy": [
        0.2517,
        0.3644,
        0.423,
        0.4989,
        0.55,
        0.531,
        0.5908,
        0.5891,
        0.542,
        0.5931,
        0.5609,
        0.6052,
        0.6086,
        0.5747,
        0.6333,
        0.6494,
        0.5931,
        0.6339,
        0.6632,
        0.6782,
        0.6546,
        0.6897,
        0.6506,
        0.6391,
        0.6299,
        0.7034,
        0.6891,
        0.6695,
        0.7034,
        0.6937,
        0.6977,
        0.7098,
        0.6799,
        0.6966,
        0.7086,
        0.7259,
        0.7218,
        0.7213,
        0.719,
        0.7161,
        0.6943,
        0.7086,
        0.7172,
        0.6741,
        0.7011,
        0.7356,
        0.7322,
        0.7299,
        0.7437,
        0.7466,
        0.7523,
        0.7224,
        0.7489,
        0.7477,
        0.7466,
        0.7621,
        0.7414,
        0.7506,
        0.7667,
        0.7672,
        0.7626,
        0.7207,
        0.7506,
        0.7724,
        0.7632,
        0.754,
        0.7661,
        0.7621,
        0.7753,
        0.769,
        0.7695,
        0.7816,
        0.7695,
        0.7868,
        0.7701,
        0.7937,
        0.7914,
        0.7943,
        0.7994,
        0.7931,
        0.7845,
        0.8029,
        0.7839,
        0.7914,
        0.8006,
        0.796,
        0.792,
        0.8006,
        0.7897,
        0.8017,
        0.8126,
        0.7908,
        0.7948,
        0.8109,
        0.8052,
        0.8086,
        0.8075,
        0.8034,
        0.808,
        0.8069,
        0.8052,
        0.8149,
        0.8046,
        0.8161,
        0.8132,
        0.8195,
        0.8115,
        0.8172,
        0.8149,
        0.8167,
        0.8259,
        0.8259,
        0.8184,
        0.8241,
        0.8264,
        0.8276,
        0.823,
        0.8184,
        0.8224,
        0.827,
        0.8259,
        0.8247,
        0.8276,
        0.8247,
        0.8293
      ]
    }
  },
  "audio_pooling_lstm_attention_20250329_080139": {
    "log_file": "emotion_training_logs/training_audio_pooling_lstm_attention_20250329_080139.log",
    "summary": {
      "epochs_completed": 125,
      "latest_val_accuracy": 0.8092,
      "best_val_accuracy": 0.8126,
      "best_epoch": 119,
      "recent_trend": -0.00029999999999995894
    },
    "metrics": {
      "epoch": [
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12,
        13,
        14,
        15,
        16,
        17,
        18,
        19,
        20,
        21,
        22,
        23,
        24,
        25,
        26,
        27,
        28,
        29,
        30,
        31,
        32,
        33,
        34,
        35,
        36,
        37,
        38,
        39,
        40,
        41,
        42,
        43,
        44,
        45,
        46,
        47,
        48,
        49,
        50,
        51,
        52,
        53,
        54,
        55,
        56,
        57,
        58,
        59,
        60,
        61,
        62,
        63,
        64,
        65,
        66,
        67,
        68,
        69,
        70,
        71,
        72,
        73,
        74,
        75,
        76,
        77,
        78,
        79,
        80,
        81,
        82,
        83,
        84,
        85,
        86,
        87,
        88,
        89,
        90,
        91,
        92,
        93,
        94,
        95,
        96,
        97,
        98,
        99,
        100,
        101,
        102,
        103,
        104,
        105,
        106,
        107,
        108,
        109,
        110,
        111,
        112,
        113,
        114,
        115,
        116,
        117,
        118,
        119,
        120,
        121,
        122,
        123,
        124,
        125
      ],
      "val_accuracy": [
        0.3121,
        0.431,
        0.4902,
        0.5621,
        0.6563,
        0.6971,
        0.6971,
        0.7178,
        0.6994,
        0.7282,
        0.7138,
        0.731,
        0.7362,
        0.7333,
        0.7218,
        0.7224,
        0.7374,
        0.7517,
        0.7511,
        0.7534,
        0.7483,
        0.7845,
        0.7345,
        0.723,
        0.7402,
        0.7718,
        0.758,
        0.7615,
        0.7621,
        0.758,
        0.7638,
        0.7534,
        0.7862,
        0.7718,
        0.7713,
        0.7724,
        0.7776,
        0.7799,
        0.7759,
        0.7644,
        0.7678,
        0.7885,
        0.7695,
        0.7816,
        0.7856,
        0.792,
        0.7902,
        0.7753,
        0.7856,
        0.7805,
        0.7868,
        0.7856,
        0.773,
        0.777,
        0.777,
        0.7902,
        0.7753,
        0.7724,
        0.7736,
        0.7747,
        0.7897,
        0.781,
        0.8017,
        0.7931,
        0.7805,
        0.7747,
        0.7684,
        0.7874,
        0.8063,
        0.7925,
        0.7833,
        0.7943,
        0.7948,
        0.7787,
        0.7874,
        0.7839,
        0.7943,
        0.7943,
        0.7948,
        0.792,
        0.7845,
        0.8057,
        0.7902,
        0.7948,
        0.8034,
        0.8,
        0.7862,
        0.7994,
        0.7977,
        0.8017,
        0.796,
        0.8075,
        0.8115,
        0.8109,
        0.7994,
        0.808,
        0.7966,
        0.8011,
        0.8115,
        0.804,
        0.8017,
        0.8092,
        0.8052,
        0.8057,
        0.8,
        0.8023,
        0.8017,
        0.8006,
        0.8034,
        0.8052,
        0.8075,
        0.8057,
        0.808,
        0.8057,
        0.804,
        0.808,
        0.8057,
        0.8057,
        0.8126,
        0.8103,
        0.8115,
        0.8103,
        0.8098,
        0.8109,
        0.8092
      ]
    }
  },
  "spectrogram_cnn_lstm_20250331_014144": {
    "log_file": "emotion_training_logs/training_spectrogram_cnn_lstm_20250331_014144.log",
    "summary": {
      "epochs_completed": 76,
      "latest_val_accuracy": 0.7966,
      "best_val_accuracy": 0.7966,
      "best_epoch": 76,
      "recent_trend": 0.002300000000000035
    },
    "metrics": {
      "epoch": [
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12,
        13,
        14,
        15,
        16,
        17,
        18,
        19,
        20,
        21,
        22,
        23,
        24,
        25,
        26,
        27,
        28,
        29,
        30,
        31,
        32,
        33,
        34,
        35,
        36,
        37,
        38,
        39,
        40,
        41,
        42,
        43,
        44,
        45,
        46,
        47,
        48,
        49,
        50,
        51,
        52,
        53,
        54,
        55,
        56,
        57,
        58,
        59,
        60,
        61,
        62,
        63,
        64,
        65,
        66,
        67,
        68,
        69,
        70,
        71,
        72,
        73,
        74,
        75,
        76
      ],
      "val_accuracy": [
        0.1684,
        0.1684,
        0.1684,
        0.2161,
        0.2328,
        0.2839,
        0.2569,
        0.3822,
        0.4943,
        0.5241,
        0.5241,
        0.6017,
        0.5609,
        0.619,
        0.6213,
        0.6489,
        0.6356,
        0.6126,
        0.6523,
        0.6322,
        0.6563,
        0.6529,
        0.696,
        0.696,
        0.6764,
        0.6793,
        0.692,
        0.719,
        0.6862,
        0.7161,
        0.7282,
        0.7264,
        0.6994,
        0.7236,
        0.7241,
        0.7241,
        0.7414,
        0.7414,
        0.7103,
        0.7494,
        0.7351,
        0.7201,
        0.7471,
        0.7351,
        0.7184,
        0.7494,
        0.746,
        0.7224,
        0.7644,
        0.7529,
        0.7506,
        0.7799,
        0.7626,
        0.7431,
        0.7787,
        0.7787,
        0.7557,
        0.7609,
        0.7529,
        0.7776,
        0.7822,
        0.7626,
        0.7638,
        0.777,
        0.7724,
        0.7828,
        0.7799,
        0.7713,
        0.7828,
        0.7937,
        0.7793,
        0.7862,
        0.7661,
        0.792,
        0.7937,
        0.7966
      ]
    }
  },
  "spectrogram_cnn_lstm_20250331_013617": {
    "log_file": "emotion_training_logs/training_spectrogram_cnn_lstm_20250331_013617.log",
    "summary": {
      "epochs_completed": 3,
      "latest_val_accuracy": 0.1787,
      "best_val_accuracy": 0.1787,
      "best_epoch": 3,
      "recent_trend": 0.005149999999999973
    },
    "metrics": {
      "epoch": [
        1,
        2,
        3
      ],
      "val_accuracy": [
        0.1684,
        0.1684,
        0.1787
      ]
    }
  },
  "precomputed_cnn_lstm_20250405_195820": {
    "log_file": "emotion_training_logs/training_precomputed_cnn_lstm_20250405_195820.log",
    "summary": {
      "epochs_completed": 140,
      "latest_val_accuracy": 0.8264,
      "best_val_accuracy": 0.8385,
      "best_epoch": 139,
      "recent_trend": -0.004349999999999685
    },
    "metrics": {
      "epoch": [
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12,
        13,
        14,
        15,
        16,
        17,
        18,
        19,
        20,
        21,
        22,
        23,
        24,
        25,
        26,
        27,
        28,
        29,
        30,
        31,
        32,
        33,
        34,
        35,
        36,
        37,
        38,
        39,
        40,
        41,
        42,
        43,
        44,
        45,
        46,
        47,
        48,
        49,
        50,
        51,
        52,
        53,
        54,
        55,
        56,
        57,
        58,
        59,
        60,
        61,
        62,
        63,
        64,
        65,
        66,
        67,
        68,
        69,
        70,
        71,
        72,
        73,
        74,
        75,
        76,
        77,
        78,
        79,
        80,
        81,
        82,
        83,
        84,
        85,
        86,
        87,
        88,
        89,
        90,
        91,
        92,
        93,
        94,
        95,
        96,
        97,
        98,
        99,
        100,
        101,
        102,
        103,
        104,
        105,
        106,
        107,
        108,
        109,
        110,
        111,
        112,
        113,
        114,
        115,
        116,
        117,
        118,
        119,
        120,
        121,
        122,
        123,
        124,
        125,
        126,
        127,
        128,
        129,
        130,
        131,
        132,
        133,
        134,
        135,
        136,
        137,
        138,
        139,
        140
      ],
      "val_accuracy": [
        0.1891,
        0.1764,
        0.169,
        0.1718,
        0.2241,
        0.3011,
        0.3517,
        0.4764,
        0.4948,
        0.5034,
        0.5557,
        0.554,
        0.5443,
        0.5914,
        0.6092,
        0.6351,
        0.6397,
        0.6638,
        0.6063,
        0.6103,
        0.6448,
        0.6701,
        0.6563,
        0.6776,
        0.6649,
        0.6707,
        0.6925,
        0.7046,
        0.7086,
        0.7052,
        0.7057,
        0.7172,
        0.7046,
        0.6868,
        0.692,
        0.6862,
        0.7448,
        0.7115,
        0.7443,
        0.6983,
        0.7391,
        0.7241,
        0.7264,
        0.7052,
        0.75,
        0.7397,
        0.7098,
        0.742,
        0.7569,
        0.7443,
        0.754,
        0.7701,
        0.7448,
        0.7534,
        0.7523,
        0.7448,
        0.7483,
        0.7649,
        0.7609,
        0.7885,
        0.7776,
        0.7632,
        0.7816,
        0.7552,
        0.7667,
        0.7943,
        0.7695,
        0.7931,
        0.7816,
        0.7902,
        0.7822,
        0.7534,
        0.7557,
        0.7822,
        0.7828,
        0.792,
        0.769,
        0.7655,
        0.8006,
        0.7943,
        0.7868,
        0.8006,
        0.7954,
        0.7891,
        0.8006,
        0.7684,
        0.7897,
        0.7994,
        0.8029,
        0.8046,
        0.8149,
        0.781,
        0.796,
        0.8092,
        0.8063,
        0.8155,
        0.8057,
        0.8172,
        0.8063,
        0.8034,
        0.8121,
        0.8276,
        0.8132,
        0.8086,
        0.827,
        0.8213,
        0.8029,
        0.8098,
        0.8138,
        0.8322,
        0.8213,
        0.8063,
        0.7994,
        0.8241,
        0.8063,
        0.8052,
        0.8195,
        0.8034,
        0.8282,
        0.8345,
        0.8155,
        0.7966,
        0.8299,
        0.8201,
        0.8167,
        0.8155,
        0.8276,
        0.8224,
        0.8322,
        0.8241,
        0.8178,
        0.8316,
        0.8333,
        0.8322,
        0.8351,
        0.8247,
        0.8316,
        0.8351,
        0.8385,
        0.8264
      ]
    }
  },
  "spectrogram_cnn_lstm_20250331_013212": {
    "log_file": "emotion_training_logs/training_spectrogram_cnn_lstm_20250331_013212.log",
    "summary": {
      "epochs_completed": 7,
      "latest_val_accuracy": 0.2805,
      "best_val_accuracy": 0.2805,
      "best_epoch": 7,
      "recent_trend": 0.04424999999999999
    },
    "metrics": {
      "epoch": [
        1,
        2,
        3,
        4,
        5,
        6,
        7
      ],
      "val_accuracy": [
        0.1897,
        0.1684,
        0.1684,
        0.181,
        0.192,
        0.2397,
        0.2805
      ]
    }
  },
  "spectrogram_20250330_222231": {
    "log_file": "emotion_training_logs/training_spectrogram_20250330_222231.log",
    "summary": {
      "epochs_completed": 2,
      "latest_val_accuracy": 0.1695,
      "best_val_accuracy": 0.1885,
      "best_epoch": 1,
      "recent_trend": null
    },
    "metrics": {
      "epoch": [
        1,
        2
      ],
      "val_accuracy": [
        0.1885,
        0.1695
      ]
    }
  },
  "precomputed_cnn_lstm_20250405_212748": {
    "log_file": "emotion_training_logs/training_precomputed_cnn_lstm_20250405_212748.log",
    "summary": {
      "epochs_completed": 51,
      "latest_val_accuracy": 0.7592,
      "best_val_accuracy": 0.7592,
      "best_epoch": 51,
      "recent_trend": 0.0051499999999999645
    },
    "metrics": {
      "epoch": [
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12,
        13,
        14,
        15,
        16,
        17,
        18,
        19,
        20,
        21,
        22,
        23,
        24,
        25,
        26,
        27,
        28,
        29,
        30,
        31,
        32,
        33,
        34,
        35,
        36,
        37,
        38,
        39,
        40,
        41,
        42,
        43,
        44,
        45,
        46,
        47,
        48,
        49,
        50,
        51
      ],
      "val_accuracy": [
        0.1833,
        0.1931,
        0.2,
        0.2144,
        0.2563,
        0.2425,
        0.3316,
        0.3937,
        0.4678,
        0.4195,
        0.4736,
        0.5155,
        0.5707,
        0.6132,
        0.5425,
        0.5902,
        0.6132,
        0.6287,
        0.6213,
        0.6517,
        0.6489,
        0.6661,
        0.6741,
        0.6713,
        0.6655,
        0.6908,
        0.6879,
        0.6759,
        0.7046,
        0.6897,
        0.6793,
        0.7333,
        0.7017,
        0.6862,
        0.7224,
        0.7184,
        0.7471,
        0.7121,
        0.7322,
        0.7391,
        0.7109,
        0.75,
        0.7385,
        0.7529,
        0.7339,
        0.7557,
        0.7552,
        0.7477,
        0.7489,
        0.7477,
        0.7592
      ]
    }
  },
  "branched_focal_loss": {
    "log_file": "emotion_training_logs/training_branched_focal_loss.log",
    "summary": {
      "epochs_completed": 50,
      "latest_val_accuracy": 0.8211,
      "best_val_accuracy": 0.8217,
      "best_epoch": 48,
      "recent_trend": -0.00029999999999999255
    },
    "metrics": {
      "epoch": [
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12,
        13,
        14,
        15,
        16,
        17,
        18,
        19,
        20,
        21,
        22,
        23,
        24,
        25,
        26,
        27,
        28,
        29,
        30,
        31,
        32,
        33,
        34,
        35,
        36,
        37,
        38,
        39,
        40,
        41,
        42,
        43,
        44,
        45,
        46,
        47,
        48,
        49,
        50
      ],
      "val_accuracy": [
        0.3414,
        0.4004,
        0.419,
        0.4567,
        0.5017,
        0.5129,
        0.5596,
        0.5754,
        0.5883,
        0.622,
        0.622,
        0.6519,
        0.6738,
        0.7058,
        0.6997,
        0.7036,
        0.7058,
        0.7323,
        0.7222,
        0.7233,
        0.77,
        0.7508,
        0.7525,
        0.7565,
        0.7503,
        0.7525,
        0.806,
        0.7897,
        0.793,
        0.7913,
        0.7694,
        0.7891,
        0.8088,
        0.8009,
        0.7975,
        0.8144,
        0.8195,
        0.8211,
        0.8172,
        0.8099,
        0.8127,
        0.8161,
        0.8138,
        0.8166,
        0.8189,
        0.8183,
        0.82,
        0.8217,
        0.8144,
        0.8211
      ]
    }
  },
  "hybrid_attention_training": {
    "log_file": "emotion_training_logs/training_hybrid_attention_training.log",
    "summary": {
      "epochs_completed": 31,
      "latest_val_accuracy": 0.6794,
      "best_val_accuracy": 0.7002,
      "best_epoch": 21,
      "recent_trend": 0.002499999999999909
    },
    "metrics": {
      "epoch": [
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12,
        13,
        14,
        15,
        16,
        17,
        18,
        19,
        20,
        21,
        22,
        23,
        24,
        25,
        26,
        27,
        28,
        29,
        30,
        31
      ],
      "val_accuracy": [
        0.3673,
        0.419,
        0.4561,
        0.4561,
        0.5034,
        0.4927,
        0.5281,
        0.581,
        0.5917,
        0.5697,
        0.6147,
        0.6316,
        0.6592,
        0.6282,
        0.6406,
        0.6457,
        0.6012,
        0.6552,
        0.6845,
        0.694,
        0.7002,
        0.6822,
        0.6811,
        0.676,
        0.6912,
        0.6879,
        0.6895,
        0.6862,
        0.6744,
        0.6783,
        0.6794
      ]
    }
  },
  "spectrogram_20250330_230900": {
    "log_file": "emotion_training_logs/training_spectrogram_20250330_230900.log",
    "summary": {
      "epochs_completed": 125,
      "latest_val_accuracy": 0.8402,
      "best_val_accuracy": 0.8443,
      "best_epoch": 122,
      "recent_trend": -0.0003000000000000314
    },
    "metrics": {
      "epoch": [
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12,
        13,
        14,
        15,
        16,
        17,
        18,
        19,
        20,
        21,
        22,
        23,
        24,
        25,
        26,
        27,
        28,
        29,
        30,
        31,
        32,
        33,
        34,
        35,
        36,
        37,
        38,
        39,
        40,
        41,
        42,
        43,
        44,
        45,
        46,
        47,
        48,
        49,
        50,
        51,
        52,
        53,
        54,
        55,
        56,
        57,
        58,
        59,
        60,
        61,
        62,
        63,
        64,
        65,
        66,
        67,
        68,
        69,
        70,
        71,
        72,
        73,
        74,
        75,
        76,
        77,
        78,
        79,
        80,
        81,
        82,
        83,
        84,
        85,
        86,
        87,
        88,
        89,
        90,
        91,
        92,
        93,
        94,
        95,
        96,
        97,
        98,
        99,
        100,
        101,
        102,
        103,
        104,
        105,
        106,
        107,
        108,
        109,
        110,
        111,
        112,
        113,
        114,
        115,
        116,
        117,
        118,
        119,
        120,
        121,
        122,
        123,
        124,
        125
      ],
      "val_accuracy": [
        0.223,
        0.1713,
        0.1764,
        0.1983,
        0.2247,
        0.2724,
        0.4029,
        0.4609,
        0.4569,
        0.4718,
        0.5184,
        0.5805,
        0.5667,
        0.5695,
        0.5891,
        0.6086,
        0.6126,
        0.6017,
        0.6477,
        0.6379,
        0.6356,
        0.6667,
        0.6437,
        0.6805,
        0.6782,
        0.6902,
        0.6787,
        0.6966,
        0.7126,
        0.6914,
        0.6874,
        0.7149,
        0.7207,
        0.7351,
        0.7259,
        0.7224,
        0.723,
        0.7322,
        0.7161,
        0.7437,
        0.7511,
        0.7466,
        0.7184,
        0.6891,
        0.7511,
        0.7092,
        0.7557,
        0.754,
        0.7511,
        0.7247,
        0.7437,
        0.7557,
        0.7586,
        0.7586,
        0.7471,
        0.7684,
        0.7782,
        0.7868,
        0.7776,
        0.7741,
        0.7862,
        0.7885,
        0.7868,
        0.7833,
        0.7833,
        0.769,
        0.7799,
        0.8063,
        0.808,
        0.7897,
        0.7764,
        0.7948,
        0.8023,
        0.8092,
        0.7885,
        0.8149,
        0.8069,
        0.8115,
        0.8126,
        0.8098,
        0.7954,
        0.8132,
        0.8069,
        0.8029,
        0.819,
        0.8063,
        0.8052,
        0.8195,
        0.8138,
        0.8253,
        0.808,
        0.8305,
        0.8149,
        0.808,
        0.8201,
        0.8316,
        0.8207,
        0.8287,
        0.8218,
        0.8328,
        0.8328,
        0.827,
        0.8368,
        0.8236,
        0.8247,
        0.8287,
        0.8368,
        0.8368,
        0.8293,
        0.8299,
        0.8299,
        0.8368,
        0.8276,
        0.8379,
        0.8345,
        0.8374,
        0.8368,
        0.8356,
        0.8351,
        0.8345,
        0.842,
        0.8443,
        0.8408,
        0.8397,
        0.8402
      ]
    }
  },
  "spectrogram_20250330_222323": {
    "log_file": "emotion_training_logs/training_spectrogram_20250330_222323.log",
    "summary": {
      "epochs_completed": 1,
      "latest_val_accuracy": 0.1678,
      "best_val_accuracy": 0.1678,
      "best_epoch": 1,
      "recent_trend": null
    },
    "metrics": {
      "epoch": [
        1
      ],
      "val_accuracy": [
        0.1678
      ]
    }
  },
  "branched_regularization_sync_aug_tcn_large_fixed_v20250327_184916": {
    "log_file": "emotion_training_logs/training_branched_regularization_sync_aug_tcn_large_fixed_v20250327_184916.log",
    "summary": {
      "epochs_completed": 81,
      "latest_val_accuracy": 0.8034,
      "best_val_accuracy": 0.8034,
      "best_epoch": 81,
      "recent_trend": 0.008599999999999653
    },
    "metrics": {
      "epoch": [
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12,
        13,
        14,
        15,
        16,
        17,
        18,
        19,
        20,
        21,
        22,
        23,
        24,
        25,
        26,
        27,
        28,
        29,
        30,
        31,
        32,
        33,
        34,
        35,
        36,
        37,
        38,
        39,
        40,
        41,
        42,
        43,
        44,
        45,
        46,
        47,
        48,
        49,
        50,
        51,
        52,
        53,
        54,
        55,
        56,
        57,
        58,
        59,
        60,
        61,
        62,
        63,
        64,
        65,
        66,
        67,
        68,
        69,
        70,
        71,
        72,
        73,
        74,
        75,
        76,
        77,
        78,
        79,
        80,
        81
      ],
      "val_accuracy": [
        0.2868,
        0.3707,
        0.4092,
        0.473,
        0.5184,
        0.5828,
        0.5437,
        0.5534,
        0.5902,
        0.5948,
        0.5994,
        0.5626,
        0.631,
        0.6379,
        0.631,
        0.6333,
        0.6736,
        0.6707,
        0.6437,
        0.6655,
        0.6621,
        0.6747,
        0.6374,
        0.6943,
        0.6983,
        0.6569,
        0.7057,
        0.7109,
        0.6885,
        0.6839,
        0.6874,
        0.7092,
        0.6989,
        0.7092,
        0.6609,
        0.7126,
        0.7149,
        0.7011,
        0.7161,
        0.7195,
        0.7086,
        0.7328,
        0.7425,
        0.7391,
        0.7305,
        0.7391,
        0.7328,
        0.7356,
        0.742,
        0.7207,
        0.7356,
        0.7534,
        0.7569,
        0.7448,
        0.7443,
        0.7569,
        0.754,
        0.7661,
        0.7667,
        0.7741,
        0.7638,
        0.7603,
        0.7615,
        0.7517,
        0.7489,
        0.7494,
        0.7517,
        0.7724,
        0.7667,
        0.7672,
        0.7644,
        0.7621,
        0.7833,
        0.781,
        0.7833,
        0.7713,
        0.7816,
        0.7851,
        0.7862,
        0.777,
        0.8034
      ]
    }
  },
  "branched_regularization_sync_aug_tcn_large_fixed_v2_lr_increase_v20250327_181500": {
    "log_file": "emotion_training_logs/training_branched_regularization_sync_aug_tcn_large_fixed_v2_lr_increase_v20250327_181500.log",
    "summary": {
      "epochs_completed": 102,
      "latest_val_accuracy": 0.8236,
      "best_val_accuracy": 0.8259,
      "best_epoch": 94,
      "recent_trend": 0.006899999999999828
    },
    "metrics": {
      "epoch": [
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12,
        13,
        14,
        15,
        16,
        17,
        18,
        19,
        20,
        21,
        22,
        23,
        24,
        25,
        26,
        27,
        28,
        29,
        30,
        31,
        32,
        33,
        34,
        35,
        36,
        37,
        38,
        39,
        40,
        41,
        42,
        43,
        44,
        45,
        46,
        47,
        48,
        49,
        50,
        51,
        52,
        53,
        54,
        55,
        56,
        57,
        58,
        59,
        60,
        61,
        62,
        63,
        64,
        65,
        66,
        67,
        68,
        69,
        70,
        71,
        72,
        73,
        74,
        75,
        76,
        77,
        78,
        79,
        80,
        81,
        82,
        83,
        84,
        85,
        86,
        87,
        88,
        89,
        90,
        91,
        92,
        93,
        94,
        95,
        96,
        97,
        98,
        99,
        100,
        101,
        102
      ],
      "val_accuracy": [
        0.342,
        0.3707,
        0.4063,
        0.4902,
        0.5282,
        0.5333,
        0.5908,
        0.5707,
        0.5897,
        0.5764,
        0.5305,
        0.5701,
        0.6023,
        0.5322,
        0.5874,
        0.6011,
        0.6287,
        0.5937,
        0.5862,
        0.6425,
        0.6172,
        0.6149,
        0.6563,
        0.6391,
        0.6621,
        0.6603,
        0.6851,
        0.654,
        0.6828,
        0.6833,
        0.7006,
        0.7006,
        0.7138,
        0.6753,
        0.6948,
        0.7126,
        0.6908,
        0.7155,
        0.6776,
        0.7034,
        0.6753,
        0.6862,
        0.7017,
        0.723,
        0.7144,
        0.7282,
        0.7155,
        0.7155,
        0.7454,
        0.7328,
        0.7402,
        0.7224,
        0.742,
        0.7448,
        0.7385,
        0.7437,
        0.7603,
        0.7609,
        0.7351,
        0.7511,
        0.7466,
        0.7448,
        0.7609,
        0.7592,
        0.7598,
        0.7764,
        0.7563,
        0.7851,
        0.7563,
        0.781,
        0.7828,
        0.7701,
        0.773,
        0.7603,
        0.7638,
        0.7661,
        0.7787,
        0.8034,
        0.7787,
        0.7971,
        0.7885,
        0.7701,
        0.7902,
        0.7971,
        0.7925,
        0.7805,
        0.7914,
        0.7914,
        0.7839,
        0.7966,
        0.8023,
        0.792,
        0.8149,
        0.8259,
        0.8034,
        0.8023,
        0.8126,
        0.8132,
        0.8184,
        0.8098,
        0.8098,
        0.8236
      ]
    }
  },
  "audio_pooling_lstm_20250329_062340": {
    "log_file": "emotion_training_logs/training_audio_pooling_lstm_20250329_062340.log",
    "summary": {
      "epochs_completed": 125,
      "latest_val_accuracy": 0.8425,
      "best_val_accuracy": 0.8534,
      "best_epoch": 117,
      "recent_trend": -0.0014499999999999249
    },
    "metrics": {
      "epoch": [
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12,
        13,
        14,
        15,
        16,
        17,
        18,
        19,
        20,
        21,
        22,
        23,
        24,
        25,
        26,
        27,
        28,
        29,
        30,
        31,
        32,
        33,
        34,
        35,
        36,
        37,
        38,
        39,
        40,
        41,
        42,
        43,
        44,
        45,
        46,
        47,
        48,
        49,
        50,
        51,
        52,
        53,
        54,
        55,
        56,
        57,
        58,
        59,
        60,
        61,
        62,
        63,
        64,
        65,
        66,
        67,
        68,
        69,
        70,
        71,
        72,
        73,
        74,
        75,
        76,
        77,
        78,
        79,
        80,
        81,
        82,
        83,
        84,
        85,
        86,
        87,
        88,
        89,
        90,
        91,
        92,
        93,
        94,
        95,
        96,
        97,
        98,
        99,
        100,
        101,
        102,
        103,
        104,
        105,
        106,
        107,
        108,
        109,
        110,
        111,
        112,
        113,
        114,
        115,
        116,
        117,
        118,
        119,
        120,
        121,
        122,
        123,
        124,
        125
      ],
      "val_accuracy": [
        0.2782,
        0.3943,
        0.4759,
        0.5471,
        0.6144,
        0.6408,
        0.6937,
        0.704,
        0.6937,
        0.7023,
        0.731,
        0.7333,
        0.7448,
        0.7534,
        0.7448,
        0.7172,
        0.7483,
        0.7684,
        0.7626,
        0.7443,
        0.7586,
        0.7621,
        0.7621,
        0.7713,
        0.7695,
        0.7753,
        0.7701,
        0.7695,
        0.7724,
        0.7793,
        0.7621,
        0.7707,
        0.7839,
        0.7477,
        0.7736,
        0.758,
        0.7511,
        0.7833,
        0.7874,
        0.7787,
        0.7822,
        0.7828,
        0.7851,
        0.7874,
        0.7902,
        0.7989,
        0.7902,
        0.7977,
        0.8006,
        0.8184,
        0.7977,
        0.7874,
        0.7805,
        0.7983,
        0.7977,
        0.8075,
        0.8006,
        0.7833,
        0.8069,
        0.7931,
        0.8046,
        0.8092,
        0.8184,
        0.8167,
        0.8063,
        0.8195,
        0.8195,
        0.8195,
        0.7977,
        0.7994,
        0.8218,
        0.8092,
        0.8167,
        0.8184,
        0.8149,
        0.8144,
        0.8138,
        0.8236,
        0.8293,
        0.8305,
        0.8138,
        0.8305,
        0.819,
        0.8172,
        0.8322,
        0.827,
        0.8333,
        0.8333,
        0.8368,
        0.8241,
        0.8356,
        0.8351,
        0.8282,
        0.8247,
        0.8328,
        0.8385,
        0.8345,
        0.8448,
        0.846,
        0.8316,
        0.8402,
        0.8431,
        0.8385,
        0.8414,
        0.8448,
        0.8448,
        0.8483,
        0.8431,
        0.8425,
        0.8454,
        0.8437,
        0.8483,
        0.8454,
        0.85,
        0.8506,
        0.8471,
        0.8534,
        0.8477,
        0.8448,
        0.846,
        0.8448,
        0.8437,
        0.8454,
        0.8448,
        0.8425
      ]
    }
  },
  "rl_model": {
    "log_file": "emotion_training_logs/training_rl_model.log",
    "summary": {
      "epochs_completed": 15,
      "latest_val_accuracy": 0.1704,
      "best_val_accuracy": 0.1884,
      "best_epoch": 6,
      "recent_trend": 0.006750000000000016
    },
    "metrics": {
      "epoch": [
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12,
        13,
        14,
        15
      ],
      "val_accuracy": [
        0.1783,
        0.1524,
        0.167,
        0.176,
        0.1777,
        0.1884,
        0.1625,
        0.18,
        0.1715,
        0.167,
        0.1586,
        0.1676,
        0.1569,
        0.171,
        0.1704
      ]
    }
  },
  "lstm_conv1d_cross_attention_20250329_081029": {
    "log_file": "emotion_training_logs/training_lstm_conv1d_cross_attention_20250329_081029.log",
    "summary": {
      "epochs_completed": 87,
      "latest_val_accuracy": 0.8075,
      "best_val_accuracy": 0.8264,
      "best_epoch": 61,
      "recent_trend": -0.0008500000000001587
    },
    "metrics": {
      "epoch": [
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12,
        13,
        14,
        15,
        16,
        17,
        18,
        19,
        20,
        21,
        22,
        23,
        24,
        25,
        26,
        27,
        28,
        29,
        30,
        31,
        32,
        33,
        34,
        35,
        36,
        37,
        38,
        39,
        40,
        41,
        42,
        43,
        44,
        45,
        46,
        47,
        48,
        49,
        50,
        51,
        52,
        53,
        54,
        55,
        56,
        57,
        58,
        59,
        60,
        61,
        62,
        63,
        64,
        65,
        66,
        67,
        68,
        69,
        70,
        71,
        72,
        73,
        74,
        75,
        76,
        77,
        78,
        79,
        80,
        81,
        82,
        83,
        84,
        85,
        86,
        87
      ],
      "val_accuracy": [
        0.396,
        0.4914,
        0.6592,
        0.7109,
        0.7466,
        0.7736,
        0.758,
        0.7385,
        0.7489,
        0.7569,
        0.7132,
        0.7431,
        0.7431,
        0.7557,
        0.7534,
        0.7856,
        0.7362,
        0.746,
        0.781,
        0.7856,
        0.7724,
        0.7615,
        0.7586,
        0.7534,
        0.7736,
        0.7764,
        0.7368,
        0.7592,
        0.7787,
        0.777,
        0.7776,
        0.7862,
        0.7879,
        0.7655,
        0.7672,
        0.7759,
        0.7718,
        0.7879,
        0.7971,
        0.7914,
        0.769,
        0.7845,
        0.8109,
        0.7713,
        0.8011,
        0.7931,
        0.7736,
        0.7914,
        0.7914,
        0.8046,
        0.7925,
        0.7793,
        0.7954,
        0.8138,
        0.7695,
        0.792,
        0.7868,
        0.8017,
        0.7971,
        0.819,
        0.8264,
        0.7994,
        0.7776,
        0.7908,
        0.8126,
        0.8115,
        0.7971,
        0.8006,
        0.804,
        0.7902,
        0.8017,
        0.8052,
        0.8046,
        0.8259,
        0.8086,
        0.8029,
        0.804,
        0.8126,
        0.8069,
        0.8155,
        0.8052,
        0.8172,
        0.8213,
        0.8167,
        0.8092,
        0.8155,
        0.8075
      ]
    }
  },
  "audio_pooling_transformer_encoder_20250329_082605": {
    "log_file": "emotion_training_logs/training_audio_pooling_transformer_encoder_20250329_082605.log",
    "summary": {
      "epochs_completed": 125,
      "latest_val_accuracy": 0.8328,
      "best_val_accuracy": 0.8345,
      "best_epoch": 105,
      "recent_trend": 0.00029999999999999005
    },
    "metrics": {
      "epoch": [
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12,
        13,
        14,
        15,
        16,
        17,
        18,
        19,
        20,
        21,
        22,
        23,
        24,
        25,
        26,
        27,
        28,
        29,
        30,
        31,
        32,
        33,
        34,
        35,
        36,
        37,
        38,
        39,
        40,
        41,
        42,
        43,
        44,
        45,
        46,
        47,
        48,
        49,
        50,
        51,
        52,
        53,
        54,
        55,
        56,
        57,
        58,
        59,
        60,
        61,
        62,
        63,
        64,
        65,
        66,
        67,
        68,
        69,
        70,
        71,
        72,
        73,
        74,
        75,
        76,
        77,
        78,
        79,
        80,
        81,
        82,
        83,
        84,
        85,
        86,
        87,
        88,
        89,
        90,
        91,
        92,
        93,
        94,
        95,
        96,
        97,
        98,
        99,
        100,
        101,
        102,
        103,
        104,
        105,
        106,
        107,
        108,
        109,
        110,
        111,
        112,
        113,
        114,
        115,
        116,
        117,
        118,
        119,
        120,
        121,
        122,
        123,
        124,
        125
      ],
      "val_accuracy": [
        0.4178,
        0.473,
        0.496,
        0.5069,
        0.5977,
        0.5937,
        0.5983,
        0.6218,
        0.6184,
        0.6282,
        0.6293,
        0.654,
        0.6707,
        0.6897,
        0.6931,
        0.6851,
        0.6897,
        0.7264,
        0.7425,
        0.7247,
        0.7471,
        0.7362,
        0.7534,
        0.7506,
        0.7322,
        0.7552,
        0.7184,
        0.7557,
        0.7494,
        0.7489,
        0.7368,
        0.758,
        0.746,
        0.7701,
        0.7885,
        0.769,
        0.7644,
        0.7695,
        0.7569,
        0.7793,
        0.7833,
        0.7799,
        0.8069,
        0.7764,
        0.7615,
        0.7851,
        0.7684,
        0.7874,
        0.7552,
        0.8115,
        0.7914,
        0.7902,
        0.7891,
        0.7885,
        0.7943,
        0.7787,
        0.7724,
        0.7989,
        0.7833,
        0.7851,
        0.7718,
        0.8023,
        0.7736,
        0.7885,
        0.7989,
        0.7931,
        0.7948,
        0.8103,
        0.8023,
        0.8063,
        0.8115,
        0.8075,
        0.8023,
        0.8121,
        0.8046,
        0.8006,
        0.8138,
        0.8144,
        0.8103,
        0.8023,
        0.8172,
        0.8184,
        0.8029,
        0.8155,
        0.819,
        0.8098,
        0.8103,
        0.8149,
        0.8201,
        0.8138,
        0.8126,
        0.8172,
        0.819,
        0.8178,
        0.8201,
        0.8276,
        0.8132,
        0.8144,
        0.8161,
        0.8218,
        0.8276,
        0.8316,
        0.827,
        0.8293,
        0.8345,
        0.8293,
        0.8299,
        0.8287,
        0.8287,
        0.8333,
        0.8305,
        0.8293,
        0.8282,
        0.8345,
        0.8322,
        0.8259,
        0.8305,
        0.8299,
        0.8299,
        0.8322,
        0.8293,
        0.8299,
        0.8322,
        0.8299,
        0.8328
      ]
    }
  },
  "branched_regularization_sync_aug_tcn_large_fixed_v2_v20250328_051805": {
    "log_file": "emotion_training_logs/training_branched_regularization_sync_aug_tcn_large_fixed_v2_v20250328_051805.log",
    "summary": {
      "epochs_completed": 125,
      "latest_val_accuracy": 0.8213,
      "best_val_accuracy": 0.8247,
      "best_epoch": 118,
      "recent_trend": -0.0005500000000000243
    },
    "metrics": {
      "epoch": [
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12,
        13,
        14,
        15,
        16,
        17,
        18,
        19,
        20,
        21,
        22,
        23,
        24,
        25,
        26,
        27,
        28,
        29,
        30,
        31,
        32,
        33,
        34,
        35,
        36,
        37,
        38,
        39,
        40,
        41,
        42,
        43,
        44,
        45,
        46,
        47,
        48,
        49,
        50,
        51,
        52,
        53,
        54,
        55,
        56,
        57,
        58,
        59,
        60,
        61,
        62,
        63,
        64,
        65,
        66,
        67,
        68,
        69,
        70,
        71,
        72,
        73,
        74,
        75,
        76,
        77,
        78,
        79,
        80,
        81,
        82,
        83,
        84,
        85,
        86,
        87,
        88,
        89,
        90,
        91,
        92,
        93,
        94,
        95,
        96,
        97,
        98,
        99,
        100,
        101,
        102,
        103,
        104,
        105,
        106,
        107,
        108,
        109,
        110,
        111,
        112,
        113,
        114,
        115,
        116,
        117,
        118,
        119,
        120,
        121,
        122,
        123,
        124,
        125
      ],
      "val_accuracy": [
        0.3437,
        0.3672,
        0.404,
        0.496,
        0.5379,
        0.5937,
        0.5971,
        0.6092,
        0.6322,
        0.6276,
        0.5937,
        0.6057,
        0.6356,
        0.6287,
        0.6414,
        0.6391,
        0.6391,
        0.6598,
        0.6356,
        0.6626,
        0.6874,
        0.6943,
        0.6793,
        0.6902,
        0.6661,
        0.7149,
        0.7,
        0.6885,
        0.6902,
        0.681,
        0.7115,
        0.7241,
        0.704,
        0.7029,
        0.7023,
        0.7213,
        0.7103,
        0.7431,
        0.7213,
        0.7506,
        0.7339,
        0.7397,
        0.7069,
        0.7437,
        0.7293,
        0.7264,
        0.7253,
        0.7494,
        0.7471,
        0.7402,
        0.7155,
        0.7322,
        0.7632,
        0.7207,
        0.746,
        0.7494,
        0.7649,
        0.7557,
        0.7667,
        0.7718,
        0.7557,
        0.7425,
        0.769,
        0.7753,
        0.7747,
        0.7816,
        0.7586,
        0.7707,
        0.7787,
        0.7943,
        0.7736,
        0.777,
        0.7661,
        0.7914,
        0.777,
        0.7782,
        0.792,
        0.777,
        0.7925,
        0.7943,
        0.7914,
        0.7937,
        0.7989,
        0.7914,
        0.7937,
        0.7954,
        0.7948,
        0.8034,
        0.8,
        0.7937,
        0.8052,
        0.8109,
        0.8132,
        0.8103,
        0.8017,
        0.8029,
        0.8,
        0.8057,
        0.8184,
        0.8075,
        0.8201,
        0.8172,
        0.823,
        0.8224,
        0.8149,
        0.8167,
        0.8149,
        0.8115,
        0.8126,
        0.8184,
        0.8178,
        0.8138,
        0.8195,
        0.8149,
        0.8144,
        0.8201,
        0.8213,
        0.8247,
        0.8241,
        0.8224,
        0.8207,
        0.8218,
        0.8224,
        0.8218,
        0.8213
      ]
    }
  },
  "precomputed_cnn_lstm_20250405_211928": {
    "log_file": "emotion_training_logs/training_precomputed_cnn_lstm_20250405_211928.log",
    "summary": {
      "epochs_completed": 8,
      "latest_val_accuracy": 0.4287,
      "best_val_accuracy": 0.4287,
      "best_epoch": 8,
      "recent_trend": 0.09019999999999996
    },
    "metrics": {
      "epoch": [
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8
      ],
      "val_accuracy": [
        0.1701,
        0.1776,
        0.1764,
        0.2138,
        0.2115,
        0.2483,
        0.2747,
        0.4287
      ]
    }
  },
  "branched_regularization_sync_aug_tcn_large_fixed_v20250328_060012": {
    "log_file": "emotion_training_logs/training_branched_regularization_sync_aug_tcn_large_fixed_v20250328_060012.log",
    "summary": {
      "epochs_completed": 115,
      "latest_val_accuracy": 0.8184,
      "best_val_accuracy": 0.8218,
      "best_epoch": 100,
      "recent_trend": 0.00345000000000015
    },
    "metrics": {
      "epoch": [
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12,
        13,
        14,
        15,
        16,
        17,
        18,
        19,
        20,
        21,
        22,
        23,
        24,
        25,
        26,
        27,
        28,
        29,
        30,
        31,
        32,
        33,
        34,
        35,
        36,
        37,
        38,
        39,
        40,
        41,
        42,
        43,
        44,
        45,
        46,
        47,
        48,
        49,
        50,
        51,
        52,
        53,
        54,
        55,
        56,
        57,
        58,
        59,
        60,
        61,
        62,
        63,
        64,
        65,
        66,
        67,
        68,
        69,
        70,
        71,
        72,
        73,
        74,
        75,
        76,
        77,
        78,
        79,
        80,
        81,
        82,
        83,
        84,
        85,
        86,
        87,
        88,
        89,
        90,
        91,
        92,
        93,
        94,
        95,
        96,
        97,
        98,
        99,
        100,
        101,
        102,
        103,
        104,
        105,
        106,
        107,
        108,
        109,
        110,
        111,
        112,
        113,
        114,
        115
      ],
      "val_accuracy": [
        0.3345,
        0.3839,
        0.4046,
        0.4851,
        0.5368,
        0.5494,
        0.6075,
        0.5868,
        0.608,
        0.6316,
        0.5937,
        0.5868,
        0.6213,
        0.6172,
        0.6328,
        0.642,
        0.6517,
        0.6615,
        0.6023,
        0.6667,
        0.6437,
        0.6609,
        0.6454,
        0.6506,
        0.6891,
        0.6937,
        0.6471,
        0.6776,
        0.6747,
        0.6989,
        0.669,
        0.7103,
        0.6874,
        0.7224,
        0.7299,
        0.7201,
        0.7305,
        0.7155,
        0.7167,
        0.6994,
        0.7241,
        0.6937,
        0.731,
        0.7437,
        0.7374,
        0.7328,
        0.7592,
        0.75,
        0.7448,
        0.7557,
        0.7563,
        0.7293,
        0.7506,
        0.7523,
        0.7598,
        0.7592,
        0.7626,
        0.7592,
        0.7586,
        0.7736,
        0.7799,
        0.7638,
        0.754,
        0.7299,
        0.7816,
        0.7672,
        0.7816,
        0.773,
        0.7695,
        0.7672,
        0.7799,
        0.7787,
        0.7948,
        0.7891,
        0.7816,
        0.7851,
        0.7701,
        0.7874,
        0.7925,
        0.7874,
        0.7787,
        0.7851,
        0.7966,
        0.7833,
        0.8034,
        0.7891,
        0.8011,
        0.7856,
        0.7966,
        0.7851,
        0.792,
        0.7948,
        0.8098,
        0.8057,
        0.8132,
        0.8086,
        0.8017,
        0.8069,
        0.8109,
        0.8218,
        0.8029,
        0.8144,
        0.8115,
        0.8121,
        0.8098,
        0.8103,
        0.8098,
        0.8109,
        0.8109,
        0.819,
        0.8195,
        0.8144,
        0.8115,
        0.8218,
        0.8184
      ]
    }
  },
  "precomputed_cnn_lstm_20250403_214241": {
    "log_file": "emotion_training_logs/training_precomputed_cnn_lstm_20250403_214241.log",
    "summary": {
      "epochs_completed": 175,
      "latest_val_accuracy": 0.8287,
      "best_val_accuracy": 0.831,
      "best_epoch": 158,
      "recent_trend": 0.0005500000000001456
    },
    "metrics": {
      "epoch": [
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12,
        13,
        14,
        15,
        16,
        17,
        18,
        19,
        20,
        21,
        22,
        23,
        24,
        25,
        26,
        27,
        28,
        29,
        30,
        31,
        32,
        33,
        34,
        35,
        36,
        37,
        38,
        39,
        40,
        41,
        42,
        43,
        44,
        45,
        46,
        47,
        48,
        49,
        50,
        51,
        52,
        53,
        54,
        55,
        56,
        57,
        58,
        59,
        60,
        61,
        62,
        63,
        64,
        65,
        66,
        67,
        68,
        69,
        70,
        71,
        72,
        73,
        74,
        75,
        76,
        77,
        78,
        79,
        80,
        81,
        82,
        83,
        84,
        85,
        86,
        87,
        88,
        89,
        90,
        91,
        92,
        93,
        94,
        95,
        96,
        97,
        98,
        99,
        100,
        101,
        102,
        103,
        104,
        105,
        106,
        107,
        108,
        109,
        110,
        111,
        112,
        113,
        114,
        115,
        116,
        117,
        118,
        119,
        120,
        121,
        122,
        123,
        124,
        125,
        126,
        127,
        128,
        129,
        130,
        131,
        132,
        133,
        134,
        135,
        136,
        137,
        138,
        139,
        140,
        141,
        142,
        143,
        144,
        145,
        146,
        147,
        148,
        149,
        150,
        151,
        152,
        153,
        154,
        155,
        156,
        157,
        158,
        159,
        160,
        161,
        162,
        163,
        164,
        165,
        166,
        167,
        168,
        169,
        170,
        171,
        172,
        173,
        174,
        175
      ],
      "val_accuracy": [
        0.1678,
        0.1695,
        0.1724,
        0.177,
        0.2109,
        0.2983,
        0.3443,
        0.3575,
        0.4713,
        0.4511,
        0.4799,
        0.5241,
        0.5293,
        0.5477,
        0.5856,
        0.5845,
        0.6121,
        0.6006,
        0.6529,
        0.6466,
        0.6379,
        0.6454,
        0.6759,
        0.673,
        0.681,
        0.6983,
        0.7144,
        0.6971,
        0.704,
        0.7138,
        0.677,
        0.6621,
        0.7161,
        0.7345,
        0.7253,
        0.7253,
        0.7109,
        0.704,
        0.7195,
        0.7431,
        0.7379,
        0.7397,
        0.7328,
        0.7523,
        0.7615,
        0.7402,
        0.7218,
        0.7483,
        0.7379,
        0.7368,
        0.7701,
        0.754,
        0.7741,
        0.7374,
        0.7328,
        0.7638,
        0.7402,
        0.7839,
        0.7615,
        0.7759,
        0.746,
        0.7644,
        0.7799,
        0.7839,
        0.7839,
        0.7316,
        0.7747,
        0.746,
        0.7805,
        0.7943,
        0.7787,
        0.7672,
        0.7782,
        0.7741,
        0.7914,
        0.7977,
        0.7862,
        0.8006,
        0.7954,
        0.7741,
        0.7718,
        0.7879,
        0.7897,
        0.781,
        0.7908,
        0.8029,
        0.7684,
        0.8017,
        0.7994,
        0.7977,
        0.8086,
        0.7649,
        0.7994,
        0.7747,
        0.8086,
        0.8052,
        0.7856,
        0.7845,
        0.7839,
        0.808,
        0.8011,
        0.792,
        0.7948,
        0.8075,
        0.8103,
        0.8132,
        0.8161,
        0.8029,
        0.8161,
        0.7994,
        0.7943,
        0.8052,
        0.8046,
        0.8023,
        0.8144,
        0.8155,
        0.8063,
        0.8046,
        0.8172,
        0.8213,
        0.808,
        0.8132,
        0.8149,
        0.8253,
        0.8132,
        0.8201,
        0.8144,
        0.8144,
        0.8305,
        0.8121,
        0.8161,
        0.8195,
        0.8178,
        0.8241,
        0.8224,
        0.8144,
        0.8178,
        0.8207,
        0.8184,
        0.8236,
        0.8253,
        0.8287,
        0.8287,
        0.8236,
        0.8253,
        0.8218,
        0.8241,
        0.8253,
        0.8293,
        0.8276,
        0.8259,
        0.8224,
        0.8305,
        0.827,
        0.8264,
        0.8264,
        0.8241,
        0.831,
        0.827,
        0.8224,
        0.8299,
        0.8282,
        0.823,
        0.8259,
        0.8305,
        0.8293,
        0.8305,
        0.8293,
        0.827,
        0.8287,
        0.8264,
        0.8287,
        0.8276,
        0.827,
        0.8287
      ]
    }
  },
  "audio_pooling_lstm_20250403_044105": {
    "log_file": "emotion_training_logs/training_audio_pooling_lstm_20250403_044105.log",
    "summary": {
      "epochs_completed": 125,
      "latest_val_accuracy": 0.8523,
      "best_val_accuracy": 0.8563,
      "best_epoch": 105,
      "recent_trend": 0.0014499999999999249
    },
    "metrics": {
      "epoch": [
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12,
        13,
        14,
        15,
        16,
        17,
        18,
        19,
        20,
        21,
        22,
        23,
        24,
        25,
        26,
        27,
        28,
        29,
        30,
        31,
        32,
        33,
        34,
        35,
        36,
        37,
        38,
        39,
        40,
        41,
        42,
        43,
        44,
        45,
        46,
        47,
        48,
        49,
        50,
        51,
        52,
        53,
        54,
        55,
        56,
        57,
        58,
        59,
        60,
        61,
        62,
        63,
        64,
        65,
        66,
        67,
        68,
        69,
        70,
        71,
        72,
        73,
        74,
        75,
        76,
        77,
        78,
        79,
        80,
        81,
        82,
        83,
        84,
        85,
        86,
        87,
        88,
        89,
        90,
        91,
        92,
        93,
        94,
        95,
        96,
        97,
        98,
        99,
        100,
        101,
        102,
        103,
        104,
        105,
        106,
        107,
        108,
        109,
        110,
        111,
        112,
        113,
        114,
        115,
        116,
        117,
        118,
        119,
        120,
        121,
        122,
        123,
        124,
        125
      ],
      "val_accuracy": [
        0.2776,
        0.4086,
        0.4914,
        0.5489,
        0.6103,
        0.677,
        0.6879,
        0.7034,
        0.7195,
        0.7063,
        0.7276,
        0.7184,
        0.7293,
        0.7345,
        0.7632,
        0.7448,
        0.7546,
        0.7506,
        0.7333,
        0.7466,
        0.7649,
        0.7529,
        0.7603,
        0.7736,
        0.7736,
        0.7626,
        0.7552,
        0.7736,
        0.7776,
        0.7753,
        0.7874,
        0.7684,
        0.7736,
        0.773,
        0.7718,
        0.7759,
        0.792,
        0.7897,
        0.7517,
        0.7753,
        0.7983,
        0.777,
        0.7989,
        0.7764,
        0.7937,
        0.7845,
        0.7805,
        0.7902,
        0.781,
        0.7885,
        0.792,
        0.8149,
        0.8178,
        0.7994,
        0.804,
        0.8,
        0.8057,
        0.8063,
        0.8109,
        0.8149,
        0.8132,
        0.8069,
        0.827,
        0.8011,
        0.8052,
        0.8115,
        0.8092,
        0.8138,
        0.8293,
        0.8201,
        0.8253,
        0.8161,
        0.8282,
        0.827,
        0.8287,
        0.8144,
        0.823,
        0.8253,
        0.8282,
        0.8339,
        0.8333,
        0.8276,
        0.8437,
        0.8339,
        0.8299,
        0.8362,
        0.8333,
        0.8316,
        0.842,
        0.8437,
        0.8356,
        0.8402,
        0.8477,
        0.8448,
        0.8431,
        0.8368,
        0.8385,
        0.842,
        0.8408,
        0.8437,
        0.8425,
        0.8517,
        0.8466,
        0.8494,
        0.8563,
        0.8483,
        0.8506,
        0.8511,
        0.8483,
        0.8454,
        0.8477,
        0.8466,
        0.846,
        0.8471,
        0.846,
        0.8443,
        0.8483,
        0.8483,
        0.846,
        0.8489,
        0.8477,
        0.8489,
        0.8494,
        0.8511,
        0.8523
      ]
    }
  },
  "no_leakage_verification": {
    "log_file": "emotion_training_logs/training_no_leakage_verification.log",
    "summary": {
      "epochs_completed": 50,
      "latest_val_accuracy": 0.8408,
      "best_val_accuracy": 0.8414,
      "best_epoch": 45,
      "recent_trend": 2.3403616056962622e-17
    },
    "metrics": {
      "epoch": [
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12,
        13,
        14,
        15,
        16,
        17,
        18,
        19,
        20,
        21,
        22,
        23,
        24,
        25,
        26,
        27,
        28,
        29,
        30,
        31,
        32,
        33,
        34,
        35,
        36,
        37,
        38,
        39,
        40,
        41,
        42,
        43,
        44,
        45,
        46,
        47,
        48,
        49,
        50
      ],
      "val_accuracy": [
        0.3015,
        0.3661,
        0.4494,
        0.5011,
        0.5382,
        0.5934,
        0.6209,
        0.6429,
        0.6423,
        0.6603,
        0.6997,
        0.694,
        0.707,
        0.7458,
        0.7267,
        0.7537,
        0.748,
        0.757,
        0.7531,
        0.7745,
        0.7756,
        0.7778,
        0.793,
        0.7717,
        0.7891,
        0.7773,
        0.7953,
        0.7992,
        0.824,
        0.8206,
        0.8256,
        0.8245,
        0.8121,
        0.8144,
        0.8307,
        0.8301,
        0.8335,
        0.8369,
        0.833,
        0.8403,
        0.8391,
        0.8408,
        0.8397,
        0.8341,
        0.8414,
        0.8414,
        0.8386,
        0.8408,
        0.8403,
        0.8408
      ]
    }
  },
  "branched_regularization_sync_aug_tcn_large_fixed": {
    "log_file": "emotion_training_logs/training_branched_regularization_sync_aug_tcn_large_fixed.log",
    "summary": {
      "epochs_completed": 103,
      "latest_val_accuracy": 0.8109,
      "best_val_accuracy": 0.8172,
      "best_epoch": 88,
      "recent_trend": 0.002299999999999875
    },
    "metrics": {
      "epoch": [
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12,
        13,
        14,
        15,
        16,
        17,
        18,
        19,
        20,
        21,
        22,
        23,
        24,
        25,
        26,
        27,
        28,
        29,
        30,
        31,
        32,
        33,
        34,
        35,
        36,
        37,
        38,
        39,
        40,
        41,
        42,
        43,
        44,
        45,
        46,
        47,
        48,
        49,
        50,
        51,
        52,
        53,
        54,
        55,
        56,
        57,
        58,
        59,
        60,
        61,
        62,
        63,
        64,
        65,
        66,
        67,
        68,
        69,
        70,
        71,
        72,
        73,
        74,
        75,
        76,
        77,
        78,
        79,
        80,
        81,
        82,
        83,
        84,
        85,
        86,
        87,
        88,
        89,
        90,
        91,
        92,
        93,
        94,
        95,
        96,
        97,
        98,
        99,
        100,
        101,
        102,
        103
      ],
      "val_accuracy": [
        0.331,
        0.3724,
        0.4046,
        0.4638,
        0.5431,
        0.5736,
        0.5977,
        0.6075,
        0.6241,
        0.6201,
        0.5759,
        0.5845,
        0.581,
        0.6178,
        0.6425,
        0.642,
        0.6437,
        0.658,
        0.6517,
        0.6557,
        0.6592,
        0.6713,
        0.6782,
        0.6856,
        0.7,
        0.6885,
        0.6914,
        0.6764,
        0.7144,
        0.6914,
        0.6983,
        0.6954,
        0.6793,
        0.7103,
        0.7293,
        0.704,
        0.719,
        0.7218,
        0.7322,
        0.7374,
        0.7264,
        0.7368,
        0.7431,
        0.7339,
        0.7454,
        0.7282,
        0.7339,
        0.7506,
        0.7414,
        0.7569,
        0.7333,
        0.7661,
        0.7322,
        0.7368,
        0.7701,
        0.7615,
        0.7506,
        0.758,
        0.7672,
        0.754,
        0.754,
        0.7592,
        0.7753,
        0.7414,
        0.7322,
        0.7822,
        0.7736,
        0.7902,
        0.7724,
        0.7989,
        0.7914,
        0.7914,
        0.7822,
        0.781,
        0.7851,
        0.7523,
        0.7782,
        0.7925,
        0.7753,
        0.792,
        0.7966,
        0.7891,
        0.7983,
        0.7897,
        0.8006,
        0.8149,
        0.8109,
        0.8172,
        0.7718,
        0.808,
        0.8,
        0.8144,
        0.808,
        0.8098,
        0.7948,
        0.804,
        0.8172,
        0.8109,
        0.8029,
        0.8023,
        0.8063,
        0.8126,
        0.8109
      ]
    }
  },
  "branched_tcn": {
    "log_file": "emotion_training_logs/training_branched_tcn.log",
    "summary": {
      "epochs_completed": 50,
      "latest_val_accuracy": 0.8408,
      "best_val_accuracy": 0.8436,
      "best_epoch": 48,
      "recent_trend": -0.0014000000000000642
    },
    "metrics": {
      "epoch": [
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12,
        13,
        14,
        15,
        16,
        17,
        18,
        19,
        20,
        21,
        22,
        23,
        24,
        25,
        26,
        27,
        28,
        29,
        30,
        31,
        32,
        33,
        34,
        35,
        36,
        37,
        38,
        39,
        40,
        41,
        42,
        43,
        44,
        45,
        46,
        47,
        48,
        49,
        50
      ],
      "val_accuracy": [
        0.3442,
        0.3667,
        0.3971,
        0.4409,
        0.4696,
        0.5264,
        0.5697,
        0.6052,
        0.6609,
        0.6642,
        0.6659,
        0.6727,
        0.7177,
        0.7368,
        0.7008,
        0.7503,
        0.7441,
        0.7638,
        0.743,
        0.7767,
        0.7666,
        0.7975,
        0.7677,
        0.7537,
        0.7739,
        0.7902,
        0.7728,
        0.8116,
        0.802,
        0.797,
        0.8161,
        0.815,
        0.8093,
        0.8043,
        0.8166,
        0.8206,
        0.8324,
        0.8408,
        0.8285,
        0.8408,
        0.8352,
        0.8358,
        0.8369,
        0.8363,
        0.8386,
        0.8301,
        0.842,
        0.8436,
        0.8436,
        0.8408
      ]
    }
  },
  "branched_regularization": {
    "log_file": "emotion_training_logs/training_branched_regularization.log",
    "summary": {
      "epochs_completed": 74,
      "latest_val_accuracy": 0.847,
      "best_val_accuracy": 0.8481,
      "best_epoch": 64,
      "recent_trend": 0.0011000000000000883
    },
    "metrics": {
      "epoch": [
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12,
        13,
        14,
        15,
        16,
        17,
        18,
        19,
        20,
        21,
        22,
        23,
        24,
        25,
        26,
        27,
        28,
        29,
        30,
        31,
        32,
        33,
        34,
        35,
        36,
        37,
        38,
        39,
        40,
        41,
        42,
        43,
        44,
        45,
        46,
        47,
        48,
        49,
        50,
        51,
        52,
        53,
        54,
        55,
        56,
        57,
        58,
        59,
        60,
        61,
        62,
        63,
        64,
        65,
        66,
        67,
        68,
        69,
        70,
        71,
        72,
        73,
        74
      ],
      "val_accuracy": [
        0.3481,
        0.4089,
        0.4325,
        0.5051,
        0.5382,
        0.5731,
        0.6097,
        0.6434,
        0.644,
        0.6755,
        0.6985,
        0.6834,
        0.712,
        0.7103,
        0.7334,
        0.7463,
        0.7615,
        0.739,
        0.7733,
        0.7936,
        0.7823,
        0.7964,
        0.7863,
        0.77,
        0.7604,
        0.7722,
        0.7683,
        0.8138,
        0.8228,
        0.8217,
        0.8273,
        0.8144,
        0.806,
        0.8273,
        0.8386,
        0.8431,
        0.8262,
        0.833,
        0.8279,
        0.8313,
        0.8369,
        0.8369,
        0.8375,
        0.8408,
        0.8386,
        0.8436,
        0.8431,
        0.8414,
        0.8352,
        0.8363,
        0.8369,
        0.8408,
        0.8397,
        0.8425,
        0.847,
        0.8414,
        0.8431,
        0.8436,
        0.8391,
        0.842,
        0.8408,
        0.8408,
        0.8425,
        0.8481,
        0.8442,
        0.8448,
        0.8459,
        0.842,
        0.8448,
        0.8459,
        0.8448,
        0.8448,
        0.8465,
        0.847
      ]
    }
  },
  "branched_regularization_sync_aug_tcn_large_fixed_v2_20250328_182237": {
    "log_file": "emotion_training_logs/training_branched_regularization_sync_aug_tcn_large_fixed_v2_20250328_182237.log",
    "summary": {
      "epochs_completed": 125,
      "latest_val_accuracy": 0.819,
      "best_val_accuracy": 0.819,
      "best_epoch": 125,
      "recent_trend": 0.0034499999999999527
    },
    "metrics": {
      "epoch": [
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12,
        13,
        14,
        15,
        16,
        17,
        18,
        19,
        20,
        21,
        22,
        23,
        24,
        25,
        26,
        27,
        28,
        29,
        30,
        31,
        32,
        33,
        34,
        35,
        36,
        37,
        38,
        39,
        40,
        41,
        42,
        43,
        44,
        45,
        46,
        47,
        48,
        49,
        50,
        51,
        52,
        53,
        54,
        55,
        56,
        57,
        58,
        59,
        60,
        61,
        62,
        63,
        64,
        65,
        66,
        67,
        68,
        69,
        70,
        71,
        72,
        73,
        74,
        75,
        76,
        77,
        78,
        79,
        80,
        81,
        82,
        83,
        84,
        85,
        86,
        87,
        88,
        89,
        90,
        91,
        92,
        93,
        94,
        95,
        96,
        97,
        98,
        99,
        100,
        101,
        102,
        103,
        104,
        105,
        106,
        107,
        108,
        109,
        110,
        111,
        112,
        113,
        114,
        115,
        116,
        117,
        118,
        119,
        120,
        121,
        122,
        123,
        124,
        125
      ],
      "val_accuracy": [
        0.3052,
        0.3655,
        0.4057,
        0.469,
        0.4741,
        0.5868,
        0.6132,
        0.5695,
        0.6075,
        0.5753,
        0.5759,
        0.5546,
        0.5466,
        0.5902,
        0.6006,
        0.5437,
        0.5799,
        0.6264,
        0.6305,
        0.6397,
        0.6172,
        0.6362,
        0.6489,
        0.6494,
        0.6701,
        0.6598,
        0.6299,
        0.6931,
        0.6644,
        0.6994,
        0.7236,
        0.6851,
        0.7063,
        0.7,
        0.696,
        0.6937,
        0.7178,
        0.7322,
        0.7241,
        0.7259,
        0.7247,
        0.7374,
        0.7098,
        0.7529,
        0.7052,
        0.7379,
        0.7529,
        0.7557,
        0.7483,
        0.75,
        0.7385,
        0.7379,
        0.7598,
        0.7569,
        0.7649,
        0.7477,
        0.7437,
        0.7523,
        0.7569,
        0.7741,
        0.746,
        0.7695,
        0.7489,
        0.7621,
        0.7655,
        0.7655,
        0.7695,
        0.7667,
        0.7684,
        0.7621,
        0.7874,
        0.7937,
        0.7736,
        0.781,
        0.7695,
        0.781,
        0.7718,
        0.7655,
        0.7718,
        0.7707,
        0.7764,
        0.7994,
        0.7856,
        0.7787,
        0.7707,
        0.8017,
        0.7885,
        0.7931,
        0.7971,
        0.7799,
        0.796,
        0.8057,
        0.8121,
        0.7931,
        0.7753,
        0.7943,
        0.7868,
        0.8057,
        0.7971,
        0.8029,
        0.8,
        0.8046,
        0.8006,
        0.8069,
        0.8109,
        0.8,
        0.8149,
        0.8075,
        0.8092,
        0.8052,
        0.8046,
        0.8144,
        0.8063,
        0.8178,
        0.8075,
        0.8161,
        0.8109,
        0.8109,
        0.8155,
        0.8161,
        0.8144,
        0.8161,
        0.8121,
        0.8126,
        0.819
      ]
    }
  },
  "lstm_attention_no_aug": {
    "log_file": "emotion_training_logs/training_lstm_attention_no_aug.log",
    "summary": {
      "epochs_completed": 48,
      "latest_val_accuracy": 0.7553,
      "best_val_accuracy": 0.7621,
      "best_epoch": 38,
      "recent_trend": 5.4301685152282283e-17
    },
    "metrics": {
      "epoch": [
        1,
        36,
        37,
        38,
        39,
        40,
        41,
        42,
        43,
        44,
        45,
        46,
        47,
        48
      ],
      "val_accuracy": [
        0.7587,
        0.7565,
        0.7576,
        0.7621,
        0.7615,
        0.7542,
        0.7565,
        0.7576,
        0.7615,
        0.7531,
        0.7576,
        0.7553,
        0.757,
        0.7553
      ]
    }
  },
  "lstm_conv1d_attention_20250329_074756": {
    "log_file": "emotion_training_logs/training_lstm_conv1d_attention_20250329_074756.log",
    "summary": {
      "epochs_completed": 67,
      "latest_val_accuracy": 0.7839,
      "best_val_accuracy": 0.7937,
      "best_epoch": 37,
      "recent_trend": 0.0037499999999999296
    },
    "metrics": {
      "epoch": [
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12,
        13,
        14,
        15,
        16,
        17,
        18,
        19,
        20,
        21,
        22,
        23,
        24,
        25,
        26,
        27,
        28,
        29,
        30,
        31,
        32,
        33,
        34,
        35,
        36,
        37,
        38,
        39,
        40,
        41,
        42,
        43,
        44,
        45,
        46,
        47,
        48,
        49,
        50,
        51,
        52,
        53,
        54,
        55,
        56,
        57,
        58,
        59,
        60,
        61,
        62,
        63,
        64,
        65,
        66,
        67
      ],
      "val_accuracy": [
        0.3391,
        0.3879,
        0.4034,
        0.5356,
        0.6529,
        0.7029,
        0.7264,
        0.727,
        0.7207,
        0.7218,
        0.7241,
        0.723,
        0.7368,
        0.7511,
        0.7276,
        0.7236,
        0.7667,
        0.7736,
        0.7557,
        0.7431,
        0.7603,
        0.7253,
        0.7684,
        0.7897,
        0.7678,
        0.7713,
        0.758,
        0.7759,
        0.7563,
        0.7626,
        0.7546,
        0.7793,
        0.7718,
        0.769,
        0.7546,
        0.7695,
        0.7937,
        0.7592,
        0.7799,
        0.7351,
        0.7402,
        0.7805,
        0.758,
        0.7632,
        0.7833,
        0.7741,
        0.7626,
        0.7575,
        0.7598,
        0.7925,
        0.7661,
        0.7506,
        0.7569,
        0.7523,
        0.7908,
        0.7701,
        0.7603,
        0.7632,
        0.7833,
        0.7776,
        0.7845,
        0.7615,
        0.7724,
        0.7805,
        0.7764,
        0.7718,
        0.7839
      ]
    }
  },
  "branched_optimizer": {
    "log_file": "emotion_training_logs/training_branched_optimizer.log",
    "summary": {
      "epochs_completed": 84,
      "latest_val_accuracy": 0.8386,
      "best_val_accuracy": 0.8436,
      "best_epoch": 74,
      "recent_trend": 0.0008500000000000659
    },
    "metrics": {
      "epoch": [
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12,
        13,
        14,
        15,
        16,
        17,
        18,
        19,
        20,
        21,
        22,
        23,
        24,
        25,
        26,
        27,
        28,
        29,
        30,
        31,
        32,
        33,
        34,
        35,
        36,
        37,
        38,
        39,
        40,
        41,
        42,
        43,
        44,
        45,
        46,
        47,
        48,
        49,
        50,
        51,
        52,
        53,
        54,
        55,
        56,
        57,
        58,
        59,
        60,
        61,
        62,
        63,
        64,
        65,
        66,
        67,
        68,
        69,
        70,
        71,
        72,
        73,
        74,
        75,
        76,
        77,
        78,
        79,
        80,
        81,
        82,
        83,
        84
      ],
      "val_accuracy": [
        0.3408,
        0.3605,
        0.3751,
        0.4173,
        0.4511,
        0.4348,
        0.4235,
        0.4381,
        0.4606,
        0.4764,
        0.4595,
        0.4871,
        0.4854,
        0.4899,
        0.4865,
        0.4916,
        0.4471,
        0.4483,
        0.5219,
        0.5427,
        0.5489,
        0.5652,
        0.5726,
        0.5861,
        0.5872,
        0.599,
        0.6406,
        0.6423,
        0.6232,
        0.6265,
        0.6395,
        0.689,
        0.6856,
        0.6974,
        0.7081,
        0.6946,
        0.7317,
        0.7081,
        0.7233,
        0.7418,
        0.7435,
        0.7548,
        0.7418,
        0.7565,
        0.7655,
        0.7582,
        0.7666,
        0.7638,
        0.7683,
        0.7885,
        0.793,
        0.7627,
        0.7778,
        0.7345,
        0.779,
        0.779,
        0.784,
        0.7795,
        0.7891,
        0.8054,
        0.7885,
        0.7998,
        0.8273,
        0.8189,
        0.8273,
        0.829,
        0.8217,
        0.8234,
        0.8318,
        0.833,
        0.842,
        0.8341,
        0.8341,
        0.8436,
        0.8369,
        0.8408,
        0.8414,
        0.8363,
        0.8408,
        0.838,
        0.8341,
        0.8369,
        0.8375,
        0.8386
      ]
    }
  },
  "precomputed_cnn_lstm_20250406_030634": {
    "log_file": "emotion_training_logs/training_precomputed_cnn_lstm_20250406_030634.log",
    "summary": {
      "epochs_completed": 1,
      "latest_val_accuracy": 0.1764,
      "best_val_accuracy": 0.1764,
      "best_epoch": 1,
      "recent_trend": null
    },
    "metrics": {
      "epoch": [
        1
      ],
      "val_accuracy": [
        0.1764
      ]
    }
  },
  "branched_regularization_sync_aug_tcn_large": {
    "log_file": "emotion_training_logs/training_branched_regularization_sync_aug_tcn_large.log",
    "summary": {
      "epochs_completed": 20,
      "latest_val_accuracy": 0.577,
      "best_val_accuracy": 0.5862,
      "best_epoch": 5,
      "recent_trend": 0.029600000000000008
    },
    "metrics": {
      "epoch": [
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12,
        13,
        14,
        15,
        16,
        17,
        18,
        19,
        20
      ],
      "val_accuracy": [
        0.3741,
        0.4046,
        0.4632,
        0.5546,
        0.5862,
        0.5385,
        0.5563,
        0.5609,
        0.5759,
        0.4943,
        0.4885,
        0.5322,
        0.4586,
        0.5006,
        0.492,
        0.5523,
        0.5678,
        0.5178,
        0.5598,
        0.577
      ]
    }
  },
  "branched_cross_attention": {
    "log_file": "emotion_training_logs/training_branched_cross_attention.log",
    "summary": {
      "epochs_completed": 50,
      "latest_val_accuracy": 0.838,
      "best_val_accuracy": 0.8414,
      "best_epoch": 48,
      "recent_trend": -0.0017000000000000409
    },
    "metrics": {
      "epoch": [
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12,
        13,
        14,
        15,
        16,
        17,
        18,
        19,
        20,
        21,
        22,
        23,
        24,
        25,
        26,
        27,
        28,
        29,
        30,
        31,
        32,
        33,
        34,
        35,
        36,
        37,
        38,
        39,
        40,
        41,
        42,
        43,
        44,
        45,
        46,
        47,
        48,
        49,
        50
      ],
      "val_accuracy": [
        0.4561,
        0.4764,
        0.5096,
        0.5197,
        0.6164,
        0.6485,
        0.6513,
        0.6232,
        0.7025,
        0.6822,
        0.7154,
        0.7458,
        0.7441,
        0.7385,
        0.7424,
        0.7508,
        0.7666,
        0.7548,
        0.77,
        0.7733,
        0.7823,
        0.7801,
        0.7711,
        0.802,
        0.7885,
        0.7953,
        0.7936,
        0.793,
        0.7745,
        0.8256,
        0.8279,
        0.8268,
        0.8127,
        0.8127,
        0.8285,
        0.8346,
        0.829,
        0.8256,
        0.8313,
        0.833,
        0.8324,
        0.829,
        0.829,
        0.8307,
        0.8352,
        0.8318,
        0.833,
        0.8414,
        0.8335,
        0.838
      ]
    }
  },
  "branched_lstm_conv1d_20250328_200317": {
    "log_file": "emotion_training_logs/training_branched_lstm_conv1d_20250328_200317.log",
    "summary": {
      "epochs_completed": 60,
      "latest_val_accuracy": 0.7753,
      "best_val_accuracy": 0.7966,
      "best_epoch": 59,
      "recent_trend": 0.0002999999999998708
    },
    "metrics": {
      "epoch": [
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12,
        13,
        14,
        15,
        16,
        17,
        18,
        19,
        20,
        21,
        22,
        23,
        24,
        25,
        26,
        27,
        28,
        29,
        30,
        31,
        32,
        33,
        34,
        35,
        36,
        37,
        38,
        39,
        40,
        41,
        42,
        43,
        44,
        45,
        46,
        47,
        48,
        49,
        50,
        51,
        52,
        53,
        54,
        55,
        56,
        57,
        58,
        59,
        60
      ],
      "val_accuracy": [
        0.3098,
        0.3586,
        0.4023,
        0.477,
        0.527,
        0.5632,
        0.6247,
        0.6356,
        0.6443,
        0.6374,
        0.6316,
        0.6632,
        0.6609,
        0.6741,
        0.6747,
        0.6891,
        0.7063,
        0.6989,
        0.7092,
        0.7172,
        0.7092,
        0.7224,
        0.7201,
        0.731,
        0.7149,
        0.7236,
        0.7293,
        0.7414,
        0.7391,
        0.7534,
        0.7598,
        0.7368,
        0.7621,
        0.7575,
        0.7598,
        0.7695,
        0.7534,
        0.7615,
        0.7569,
        0.7678,
        0.769,
        0.7575,
        0.7615,
        0.7672,
        0.7575,
        0.7718,
        0.769,
        0.7822,
        0.7661,
        0.7655,
        0.7782,
        0.7644,
        0.7707,
        0.7741,
        0.7805,
        0.7764,
        0.7695,
        0.7747,
        0.7966,
        0.7753
      ]
    }
  },
  "precomputed_cnn_lstm_20250405_072423": {
    "log_file": "emotion_training_logs/training_precomputed_cnn_lstm_20250405_072423.log",
    "summary": {
      "epochs_completed": 175,
      "latest_val_accuracy": 0.8425,
      "best_val_accuracy": 0.8437,
      "best_epoch": 149,
      "recent_trend": -0.0002999999999999321
    },
    "metrics": {
      "epoch": [
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12,
        13,
        14,
        15,
        16,
        17,
        18,
        19,
        20,
        21,
        22,
        23,
        24,
        25,
        26,
        27,
        28,
        29,
        30,
        31,
        32,
        33,
        34,
        35,
        36,
        37,
        38,
        39,
        40,
        41,
        42,
        43,
        44,
        45,
        46,
        47,
        48,
        49,
        50,
        51,
        52,
        53,
        54,
        55,
        56,
        57,
        58,
        59,
        60,
        61,
        62,
        63,
        64,
        65,
        66,
        67,
        68,
        69,
        70,
        71,
        72,
        73,
        74,
        75,
        76,
        77,
        78,
        79,
        80,
        81,
        82,
        83,
        84,
        85,
        86,
        87,
        88,
        89,
        90,
        91,
        92,
        93,
        94,
        95,
        96,
        97,
        98,
        99,
        100,
        101,
        102,
        103,
        104,
        105,
        106,
        107,
        108,
        109,
        110,
        111,
        112,
        113,
        114,
        115,
        116,
        117,
        118,
        119,
        120,
        121,
        122,
        123,
        124,
        125,
        126,
        127,
        128,
        129,
        130,
        131,
        132,
        133,
        134,
        135,
        136,
        137,
        138,
        139,
        140,
        141,
        142,
        143,
        144,
        145,
        146,
        147,
        148,
        149,
        150,
        151,
        152,
        153,
        154,
        155,
        156,
        157,
        158,
        159,
        160,
        161,
        162,
        163,
        164,
        165,
        166,
        167,
        168,
        169,
        170,
        171,
        172,
        173,
        174,
        175
      ],
      "val_accuracy": [
        0.1943,
        0.1724,
        0.1684,
        0.2046,
        0.319,
        0.4368,
        0.3397,
        0.4592,
        0.4489,
        0.4644,
        0.4937,
        0.5201,
        0.5632,
        0.5753,
        0.5414,
        0.5971,
        0.5937,
        0.6362,
        0.669,
        0.6615,
        0.6374,
        0.6592,
        0.6954,
        0.6856,
        0.65,
        0.6753,
        0.7138,
        0.6701,
        0.6966,
        0.7132,
        0.7138,
        0.6644,
        0.7069,
        0.7023,
        0.6931,
        0.6868,
        0.7184,
        0.7057,
        0.7391,
        0.7351,
        0.7299,
        0.7414,
        0.7489,
        0.7351,
        0.7287,
        0.6948,
        0.7414,
        0.7397,
        0.7351,
        0.7046,
        0.7684,
        0.7563,
        0.7408,
        0.7598,
        0.7741,
        0.7615,
        0.7753,
        0.7414,
        0.7799,
        0.7638,
        0.7713,
        0.7718,
        0.7552,
        0.7684,
        0.758,
        0.7598,
        0.7724,
        0.777,
        0.7764,
        0.7471,
        0.7851,
        0.7626,
        0.7695,
        0.7684,
        0.7747,
        0.7885,
        0.7885,
        0.7966,
        0.8006,
        0.7868,
        0.7879,
        0.7793,
        0.7839,
        0.792,
        0.8006,
        0.7966,
        0.8034,
        0.777,
        0.7902,
        0.8098,
        0.7891,
        0.804,
        0.8098,
        0.8006,
        0.8086,
        0.8138,
        0.8213,
        0.8075,
        0.8029,
        0.8161,
        0.808,
        0.8092,
        0.8213,
        0.804,
        0.8006,
        0.8299,
        0.8167,
        0.8362,
        0.8138,
        0.8264,
        0.8057,
        0.8218,
        0.8092,
        0.8264,
        0.8322,
        0.8029,
        0.8172,
        0.823,
        0.8086,
        0.8195,
        0.8138,
        0.8259,
        0.8178,
        0.8224,
        0.827,
        0.8195,
        0.8063,
        0.8293,
        0.8213,
        0.8287,
        0.8333,
        0.8293,
        0.8339,
        0.8362,
        0.8414,
        0.8195,
        0.8299,
        0.8368,
        0.8414,
        0.8379,
        0.8247,
        0.8207,
        0.8356,
        0.8316,
        0.8305,
        0.8362,
        0.8408,
        0.8408,
        0.8437,
        0.8397,
        0.8379,
        0.842,
        0.8385,
        0.8402,
        0.8368,
        0.8368,
        0.8356,
        0.8356,
        0.8431,
        0.8402,
        0.8402,
        0.8385,
        0.842,
        0.8339,
        0.8414,
        0.8402,
        0.8397,
        0.8402,
        0.8408,
        0.8437,
        0.8408,
        0.8414,
        0.8431,
        0.8425,
        0.8425
      ]
    }
  },
  "lstm_conv1d_cross_attention_only_20250329_104749": {
    "log_file": "emotion_training_logs/training_lstm_conv1d_cross_attention_only_20250329_104749.log",
    "summary": {
      "epochs_completed": 88,
      "latest_val_accuracy": 0.8247,
      "best_val_accuracy": 0.8247,
      "best_epoch": 85,
      "recent_trend": 0.009200000000000033
    },
    "metrics": {
      "epoch": [
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12,
        13,
        14,
        15,
        16,
        17,
        18,
        19,
        20,
        21,
        22,
        23,
        24,
        25,
        26,
        27,
        28,
        29,
        30,
        31,
        32,
        33,
        34,
        35,
        36,
        37,
        38,
        39,
        40,
        41,
        42,
        43,
        44,
        45,
        46,
        47,
        48,
        49,
        50,
        51,
        52,
        53,
        54,
        55,
        56,
        57,
        58,
        59,
        60,
        61,
        62,
        63,
        64,
        65,
        66,
        67,
        68,
        69,
        70,
        71,
        72,
        73,
        74,
        75,
        76,
        77,
        78,
        79,
        80,
        81,
        82,
        83,
        84,
        85,
        86,
        87,
        88
      ],
      "val_accuracy": [
        0.3977,
        0.4644,
        0.6092,
        0.6776,
        0.7287,
        0.731,
        0.7448,
        0.7644,
        0.7397,
        0.7339,
        0.7172,
        0.7437,
        0.7471,
        0.7592,
        0.7557,
        0.7672,
        0.7707,
        0.773,
        0.7328,
        0.7603,
        0.7374,
        0.7787,
        0.7598,
        0.7471,
        0.7925,
        0.773,
        0.769,
        0.7563,
        0.7655,
        0.7713,
        0.7649,
        0.7816,
        0.7782,
        0.781,
        0.7776,
        0.7994,
        0.7793,
        0.7713,
        0.7586,
        0.7805,
        0.7747,
        0.7695,
        0.8006,
        0.75,
        0.7885,
        0.7902,
        0.7954,
        0.7954,
        0.7833,
        0.7707,
        0.7816,
        0.7879,
        0.7954,
        0.8011,
        0.7954,
        0.7931,
        0.7983,
        0.8213,
        0.7943,
        0.8161,
        0.7948,
        0.8121,
        0.7943,
        0.7902,
        0.8144,
        0.8167,
        0.8063,
        0.8115,
        0.7851,
        0.7937,
        0.8029,
        0.8161,
        0.7989,
        0.7948,
        0.8086,
        0.8057,
        0.8138,
        0.804,
        0.7943,
        0.8046,
        0.8052,
        0.8046,
        0.8017,
        0.8224,
        0.8247,
        0.8063,
        0.8224,
        0.8247
      ]
    }
  },
  "lstm_conv1d_20250328_200350": {
    "log_file": "emotion_training_logs/training_lstm_conv1d_20250328_200350.log",
    "summary": {
      "epochs_completed": 125,
      "latest_val_accuracy": 0.8322,
      "best_val_accuracy": 0.8374,
      "best_epoch": 122,
      "recent_trend": 0.00030000000000005294
    },
    "metrics": {
      "epoch": [
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12,
        13,
        14,
        15,
        16,
        17,
        18,
        19,
        20,
        21,
        22,
        23,
        24,
        25,
        26,
        27,
        28,
        29,
        30,
        31,
        32,
        33,
        34,
        35,
        36,
        37,
        38,
        39,
        40,
        41,
        42,
        43,
        44,
        45,
        46,
        47,
        48,
        49,
        50,
        51,
        52,
        53,
        54,
        55,
        56,
        57,
        58,
        59,
        60,
        61,
        62,
        63,
        64,
        65,
        66,
        67,
        68,
        69,
        70,
        71,
        72,
        73,
        74,
        75,
        76,
        77,
        78,
        79,
        80,
        81,
        82,
        83,
        84,
        85,
        86,
        87,
        88,
        89,
        90,
        91,
        92,
        93,
        94,
        95,
        96,
        97,
        98,
        99,
        100,
        101,
        102,
        103,
        104,
        105,
        106,
        107,
        108,
        109,
        110,
        111,
        112,
        113,
        114,
        115,
        116,
        117,
        118,
        119,
        120,
        121,
        122,
        123,
        124,
        125
      ],
      "val_accuracy": [
        0.3201,
        0.4115,
        0.4339,
        0.4943,
        0.5529,
        0.5529,
        0.6098,
        0.6408,
        0.6282,
        0.6506,
        0.6701,
        0.6569,
        0.658,
        0.6994,
        0.6914,
        0.7167,
        0.7063,
        0.7034,
        0.6908,
        0.7138,
        0.7287,
        0.7178,
        0.7167,
        0.7086,
        0.7534,
        0.7247,
        0.7454,
        0.7121,
        0.746,
        0.7534,
        0.7546,
        0.7603,
        0.7477,
        0.7644,
        0.7494,
        0.75,
        0.7437,
        0.7534,
        0.7678,
        0.7552,
        0.7759,
        0.7598,
        0.754,
        0.7592,
        0.7649,
        0.7764,
        0.7856,
        0.7747,
        0.7655,
        0.7632,
        0.7787,
        0.7874,
        0.7971,
        0.7937,
        0.7891,
        0.7966,
        0.7954,
        0.792,
        0.7868,
        0.7943,
        0.7925,
        0.7925,
        0.7983,
        0.7971,
        0.7937,
        0.7943,
        0.7897,
        0.804,
        0.7994,
        0.7977,
        0.8,
        0.808,
        0.8052,
        0.8006,
        0.7948,
        0.8126,
        0.8132,
        0.8172,
        0.8109,
        0.8098,
        0.7983,
        0.8247,
        0.8161,
        0.8241,
        0.8178,
        0.8121,
        0.808,
        0.8264,
        0.8224,
        0.8218,
        0.8155,
        0.8287,
        0.8167,
        0.8264,
        0.8201,
        0.8333,
        0.8236,
        0.8213,
        0.8276,
        0.8316,
        0.8305,
        0.8287,
        0.8253,
        0.8356,
        0.8236,
        0.8328,
        0.8328,
        0.8322,
        0.8282,
        0.8282,
        0.8299,
        0.8224,
        0.8253,
        0.8322,
        0.8276,
        0.8345,
        0.8293,
        0.8293,
        0.831,
        0.8299,
        0.8328,
        0.8374,
        0.8316,
        0.8339,
        0.8322
      ]
    }
  },
  "precomputed_cnn_lstm_20250403_210945": {
    "log_file": "emotion_training_logs/training_precomputed_cnn_lstm_20250403_210945.log",
    "summary": {
      "epochs_completed": 174,
      "latest_val_accuracy": 0.8236,
      "best_val_accuracy": 0.8316,
      "best_epoch": 144,
      "recent_trend": -0.000850000000000071
    },
    "metrics": {
      "epoch": [
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12,
        13,
        14,
        15,
        16,
        17,
        18,
        19,
        20,
        21,
        22,
        23,
        24,
        25,
        26,
        27,
        28,
        29,
        30,
        31,
        32,
        33,
        34,
        35,
        36,
        37,
        38,
        39,
        40,
        41,
        42,
        43,
        44,
        45,
        46,
        47,
        48,
        49,
        50,
        51,
        52,
        53,
        54,
        55,
        56,
        57,
        58,
        59,
        60,
        61,
        62,
        63,
        64,
        65,
        66,
        67,
        68,
        69,
        70,
        71,
        72,
        73,
        74,
        75,
        76,
        77,
        78,
        79,
        80,
        81,
        82,
        83,
        84,
        85,
        86,
        87,
        88,
        89,
        90,
        91,
        92,
        93,
        94,
        95,
        96,
        97,
        98,
        99,
        100,
        101,
        102,
        103,
        104,
        105,
        106,
        107,
        108,
        109,
        110,
        111,
        112,
        113,
        114,
        115,
        116,
        117,
        118,
        119,
        120,
        121,
        122,
        123,
        124,
        125,
        126,
        127,
        128,
        129,
        130,
        131,
        132,
        133,
        134,
        135,
        136,
        137,
        138,
        139,
        140,
        141,
        142,
        143,
        144,
        145,
        146,
        147,
        148,
        149,
        150,
        151,
        152,
        153,
        154,
        155,
        156,
        157,
        158,
        159,
        160,
        161,
        162,
        163,
        164,
        165,
        166,
        167,
        168,
        169,
        170,
        171,
        172,
        173,
        174
      ],
      "val_accuracy": [
        0.1845,
        0.2023,
        0.1908,
        0.1839,
        0.2218,
        0.2471,
        0.2741,
        0.4385,
        0.4218,
        0.4902,
        0.531,
        0.5391,
        0.5592,
        0.5776,
        0.5736,
        0.6236,
        0.6172,
        0.5874,
        0.6109,
        0.6132,
        0.6471,
        0.6787,
        0.6431,
        0.6736,
        0.6747,
        0.6713,
        0.7103,
        0.704,
        0.7063,
        0.7109,
        0.6879,
        0.6902,
        0.7236,
        0.7121,
        0.7017,
        0.7034,
        0.723,
        0.7126,
        0.7287,
        0.7259,
        0.7224,
        0.7293,
        0.719,
        0.7408,
        0.7299,
        0.7299,
        0.7126,
        0.7345,
        0.7397,
        0.7563,
        0.7259,
        0.727,
        0.7506,
        0.7356,
        0.731,
        0.746,
        0.7615,
        0.7701,
        0.7563,
        0.7684,
        0.7736,
        0.7569,
        0.7506,
        0.7552,
        0.7655,
        0.7155,
        0.758,
        0.7747,
        0.7638,
        0.7764,
        0.7603,
        0.7655,
        0.7713,
        0.7856,
        0.7552,
        0.7793,
        0.7626,
        0.7707,
        0.7816,
        0.781,
        0.769,
        0.7799,
        0.7759,
        0.7626,
        0.7862,
        0.7667,
        0.8057,
        0.7874,
        0.781,
        0.7931,
        0.7879,
        0.7805,
        0.7925,
        0.7753,
        0.7943,
        0.7948,
        0.7764,
        0.8029,
        0.8023,
        0.7799,
        0.7914,
        0.8029,
        0.8006,
        0.7983,
        0.8121,
        0.8098,
        0.8178,
        0.8144,
        0.8029,
        0.8063,
        0.8069,
        0.8207,
        0.8069,
        0.8213,
        0.7983,
        0.7879,
        0.8121,
        0.819,
        0.8161,
        0.8011,
        0.8115,
        0.8075,
        0.8224,
        0.8195,
        0.8207,
        0.8236,
        0.8109,
        0.8121,
        0.8103,
        0.8184,
        0.8195,
        0.8115,
        0.8253,
        0.8195,
        0.8121,
        0.8213,
        0.8144,
        0.8236,
        0.8126,
        0.8149,
        0.8264,
        0.8167,
        0.8241,
        0.8316,
        0.8178,
        0.8167,
        0.8172,
        0.823,
        0.8218,
        0.827,
        0.819,
        0.8241,
        0.827,
        0.8201,
        0.8253,
        0.8259,
        0.8224,
        0.8253,
        0.8264,
        0.8299,
        0.8264,
        0.8259,
        0.8253,
        0.8247,
        0.827,
        0.8259,
        0.8293,
        0.8247,
        0.8241,
        0.8241,
        0.8236,
        0.8253,
        0.8236,
        0.8236
      ]
    }
  },
  "branched_regularization_sync_aug_tcn_large_fixed_v2_l2_increase_v20250327_182424": {
    "log_file": "emotion_training_logs/training_branched_regularization_sync_aug_tcn_large_fixed_v2_l2_increase_v20250327_182424.log",
    "summary": {
      "epochs_completed": 102,
      "latest_val_accuracy": 0.8086,
      "best_val_accuracy": 0.8195,
      "best_epoch": 101,
      "recent_trend": 0.0003000000000000345
    },
    "metrics": {
      "epoch": [
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12,
        13,
        14,
        15,
        16,
        17,
        18,
        19,
        20,
        21,
        22,
        23,
        24,
        25,
        26,
        27,
        28,
        29,
        30,
        31,
        32,
        33,
        34,
        35,
        36,
        37,
        38,
        39,
        40,
        41,
        42,
        43,
        44,
        45,
        46,
        47,
        48,
        49,
        50,
        51,
        52,
        53,
        54,
        55,
        56,
        57,
        58,
        59,
        60,
        61,
        62,
        63,
        64,
        65,
        66,
        67,
        68,
        69,
        70,
        71,
        72,
        73,
        74,
        75,
        76,
        77,
        78,
        79,
        80,
        81,
        82,
        83,
        84,
        85,
        86,
        87,
        88,
        89,
        90,
        91,
        92,
        93,
        94,
        95,
        96,
        97,
        98,
        99,
        100,
        101,
        102
      ],
      "val_accuracy": [
        0.3385,
        0.3787,
        0.4437,
        0.5213,
        0.5448,
        0.5736,
        0.608,
        0.5575,
        0.6034,
        0.5506,
        0.5632,
        0.5902,
        0.6006,
        0.6098,
        0.6132,
        0.6282,
        0.6218,
        0.6362,
        0.6345,
        0.6569,
        0.581,
        0.6149,
        0.631,
        0.6632,
        0.6569,
        0.6575,
        0.6282,
        0.6713,
        0.6931,
        0.6914,
        0.7069,
        0.6707,
        0.6994,
        0.6914,
        0.7017,
        0.7316,
        0.6954,
        0.7167,
        0.7213,
        0.7178,
        0.7138,
        0.7172,
        0.7167,
        0.7253,
        0.7287,
        0.7506,
        0.7218,
        0.7667,
        0.7557,
        0.7299,
        0.7115,
        0.7586,
        0.7517,
        0.719,
        0.754,
        0.7264,
        0.7489,
        0.746,
        0.7506,
        0.7477,
        0.754,
        0.7517,
        0.7483,
        0.7621,
        0.7575,
        0.7144,
        0.7822,
        0.7603,
        0.7707,
        0.7586,
        0.769,
        0.754,
        0.7569,
        0.8034,
        0.769,
        0.7868,
        0.769,
        0.7787,
        0.7845,
        0.7891,
        0.792,
        0.7891,
        0.7707,
        0.7822,
        0.781,
        0.7931,
        0.796,
        0.8052,
        0.796,
        0.7805,
        0.8092,
        0.7902,
        0.808,
        0.8086,
        0.8057,
        0.8075,
        0.8092,
        0.7925,
        0.7977,
        0.808,
        0.8195,
        0.8086
      ]
    }
  },
  "spectrogram_cnn_pooling_lstm_training": {
    "log_file": "emotion_training_logs/spectrogram_cnn_pooling_lstm_training.log",
    "summary": {
      "epochs_completed": 54,
      "latest_val_accuracy": 0.2339,
      "best_val_accuracy": 0.3115,
      "best_epoch": 14,
      "recent_trend": 0.011199999999999953
    },
    "metrics": {
      "epoch": [
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12,
        13,
        14,
        15,
        16,
        17,
        18,
        19,
        20,
        21,
        22,
        23,
        24,
        25,
        26,
        27,
        28,
        29,
        30,
        31,
        32,
        33,
        34,
        35,
        36,
        37,
        38,
        39,
        40,
        41,
        42,
        43,
        44,
        45,
        46,
        47,
        48,
        49,
        50,
        51,
        52,
        53,
        54
      ],
      "val_accuracy": [
        0.1672,
        0.1667,
        0.1701,
        0.1569,
        0.169,
        0.1684,
        0.1684,
        0.1684,
        0.1684,
        0.1713,
        0.2149,
        0.269,
        0.2557,
        0.3115,
        0.1868,
        0.181,
        0.169,
        0.1672,
        0.1741,
        0.1667,
        0.1672,
        0.1649,
        0.1672,
        0.1684,
        0.1684,
        0.1684,
        0.1684,
        0.1655,
        0.1684,
        0.1684,
        0.1684,
        0.1655,
        0.1667,
        0.1793,
        0.1989,
        0.2109,
        0.2172,
        0.2224,
        0.1856,
        0.204,
        0.1828,
        0.1931,
        0.192,
        0.1816,
        0.2241,
        0.2241,
        0.2218,
        0.2103,
        0.2052,
        0.223,
        0.2253,
        0.2115,
        0.2264,
        0.2339
      ]
    }
  },
  "branched_regularization_sync_aug": {
    "log_file": "emotion_training_logs/training_branched_regularization_sync_aug.log",
    "summary": {
      "epochs_completed": 45,
      "latest_val_accuracy": 0.8285,
      "best_val_accuracy": 0.8346,
      "best_epoch": 35,
      "recent_trend": -0.00025000000000007964
    },
    "metrics": {
      "epoch": [
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12,
        13,
        14,
        15,
        16,
        17,
        18,
        19,
        20,
        21,
        22,
        23,
        24,
        25,
        26,
        27,
        28,
        29,
        30,
        31,
        32,
        33,
        34,
        35,
        36,
        37,
        38,
        39,
        40,
        41,
        42,
        43,
        44,
        45
      ],
      "val_accuracy": [
        0.3858,
        0.4595,
        0.5253,
        0.5709,
        0.6125,
        0.6305,
        0.7081,
        0.6642,
        0.716,
        0.7435,
        0.7267,
        0.7503,
        0.7407,
        0.7587,
        0.7627,
        0.7638,
        0.779,
        0.7503,
        0.7542,
        0.7998,
        0.7829,
        0.7807,
        0.8009,
        0.8048,
        0.806,
        0.7897,
        0.8166,
        0.8003,
        0.8065,
        0.8082,
        0.7942,
        0.7987,
        0.8285,
        0.8256,
        0.8346,
        0.8245,
        0.8279,
        0.824,
        0.8273,
        0.8262,
        0.8301,
        0.8245,
        0.829,
        0.8279,
        0.8285
      ]
    }
  },
  "spectrogram_20250330_222605": {
    "log_file": "emotion_training_logs/training_spectrogram_20250330_222605.log",
    "summary": {
      "epochs_completed": 37,
      "latest_val_accuracy": 0.7247,
      "best_val_accuracy": 0.7259,
      "best_epoch": 36,
      "recent_trend": 0.008350000000000026
    },
    "metrics": {
      "epoch": [
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12,
        13,
        14,
        15,
        16,
        17,
        18,
        19,
        20,
        21,
        22,
        23,
        24,
        25,
        26,
        27,
        28,
        29,
        30,
        31,
        32,
        33,
        34,
        35,
        36,
        37
      ],
      "val_accuracy": [
        0.1707,
        0.1948,
        0.1787,
        0.2086,
        0.2443,
        0.2684,
        0.3506,
        0.4557,
        0.304,
        0.4822,
        0.508,
        0.5351,
        0.504,
        0.5477,
        0.5851,
        0.5787,
        0.5874,
        0.6431,
        0.6402,
        0.6374,
        0.6356,
        0.6534,
        0.6563,
        0.6713,
        0.6776,
        0.6776,
        0.7052,
        0.6954,
        0.6655,
        0.7057,
        0.7213,
        0.6879,
        0.6908,
        0.719,
        0.708,
        0.7259,
        0.7247
      ]
    }
  },
  "wav2vec_transformer_20250331_014341": {
    "log_file": "emotion_training_logs/training_wav2vec_transformer_20250331_014341.log",
    "summary": {
      "epochs_completed": 5,
      "latest_val_accuracy": 0.1684,
      "best_val_accuracy": 0.1943,
      "best_epoch": 1,
      "recent_trend": -0.00029999999999998154
    },
    "metrics": {
      "epoch": [
        1,
        2,
        3,
        4,
        5
      ],
      "val_accuracy": [
        0.1943,
        0.1684,
        0.169,
        0.1684,
        0.1684
      ]
    }
  },
  "wav2vec_transformer_20250331_005311": {
    "log_file": "emotion_training_logs/training_wav2vec_transformer_20250331_005311.log",
    "summary": {
      "epochs_completed": 1,
      "latest_val_accuracy": 0.1822,
      "best_val_accuracy": 0.1822,
      "best_epoch": 1,
      "recent_trend": null
    },
    "metrics": {
      "epoch": [
        1
      ],
      "val_accuracy": [
        0.1822
      ]
    }
  },
  "branched_sync_aug": {
    "log_file": "emotion_training_logs/training_branched_sync_aug.log",
    "summary": {
      "epochs_completed": 50,
      "latest_val_accuracy": 0.8453,
      "best_val_accuracy": 0.8453,
      "best_epoch": 50,
      "recent_trend": 0.0013999999999999412
    },
    "metrics": {
      "epoch": [
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12,
        13,
        14,
        15,
        16,
        17,
        18,
        19,
        20,
        21,
        22,
        23,
        24,
        25,
        26,
        27,
        28,
        29,
        30,
        31,
        32,
        33,
        34,
        35,
        36,
        37,
        38,
        39,
        40,
        41,
        42,
        43,
        44,
        45,
        46,
        47,
        48,
        49,
        50
      ],
      "val_accuracy": [
        0.3836,
        0.4291,
        0.4668,
        0.4921,
        0.5433,
        0.5866,
        0.6232,
        0.6586,
        0.6884,
        0.707,
        0.7272,
        0.7295,
        0.7328,
        0.7593,
        0.752,
        0.7649,
        0.7627,
        0.788,
        0.7784,
        0.7728,
        0.7829,
        0.7987,
        0.7846,
        0.7818,
        0.8211,
        0.8138,
        0.811,
        0.8099,
        0.8195,
        0.8195,
        0.833,
        0.8301,
        0.838,
        0.8307,
        0.8273,
        0.8307,
        0.8363,
        0.833,
        0.8352,
        0.8375,
        0.8403,
        0.8414,
        0.8436,
        0.842,
        0.8414,
        0.8448,
        0.8431,
        0.8425,
        0.8442,
        0.8453
      ]
    }
  },
  "branched_lstm_conv1d_20250403_114037": {
    "log_file": "emotion_training_logs/training_branched_lstm_conv1d_20250403_114037.log",
    "summary": {
      "epochs_completed": 32,
      "latest_val_accuracy": 0.7862,
      "best_val_accuracy": 0.8144,
      "best_epoch": 2,
      "recent_trend": 0.0005499999999999862
    },
    "metrics": {
      "epoch": [
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12,
        13,
        14,
        15,
        16,
        17,
        18,
        19,
        20,
        21,
        22,
        23,
        24,
        25,
        26,
        27,
        28,
        29,
        30,
        31,
        32
      ],
      "val_accuracy": [
        0.8138,
        0.8144,
        0.8,
        0.804,
        0.8057,
        0.7764,
        0.7684,
        0.7908,
        0.7489,
        0.7615,
        0.7874,
        0.75,
        0.7793,
        0.7603,
        0.7603,
        0.7759,
        0.7672,
        0.7598,
        0.7724,
        0.7805,
        0.7592,
        0.7649,
        0.7632,
        0.7672,
        0.758,
        0.7644,
        0.7701,
        0.7839,
        0.7908,
        0.7851,
        0.7621,
        0.7862
      ]
    }
  },
  "branched_regularization_sync_aug_tcn_large_fixed_v2": {
    "log_file": "emotion_training_logs/training_branched_regularization_sync_aug_tcn_large_fixed_v2.log",
    "summary": {
      "epochs_completed": 86,
      "latest_val_accuracy": 0.7868,
      "best_val_accuracy": 0.8017,
      "best_epoch": 85,
      "recent_trend": -0.003449999999999795
    },
    "metrics": {
      "epoch": [
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12,
        13,
        14,
        15,
        16,
        17,
        18,
        19,
        20,
        21,
        22,
        23,
        24,
        25,
        26,
        27,
        28,
        29,
        30,
        31,
        32,
        33,
        34,
        35,
        36,
        37,
        38,
        39,
        40,
        41,
        42,
        43,
        44,
        45,
        46,
        47,
        48,
        49,
        50,
        51,
        52,
        53,
        54,
        55,
        56,
        57,
        58,
        59,
        60,
        61,
        62,
        63,
        64,
        65,
        66,
        67,
        68,
        69,
        70,
        71,
        72,
        73,
        74,
        75,
        76,
        77,
        78,
        79,
        80,
        81,
        82,
        83,
        84,
        85,
        86
      ],
      "val_accuracy": [
        0.3098,
        0.3511,
        0.4023,
        0.4477,
        0.5253,
        0.5914,
        0.5885,
        0.6006,
        0.5925,
        0.5937,
        0.6017,
        0.5368,
        0.5833,
        0.6259,
        0.6046,
        0.5782,
        0.6489,
        0.6707,
        0.6391,
        0.6517,
        0.6144,
        0.6644,
        0.6615,
        0.6753,
        0.6701,
        0.6523,
        0.6782,
        0.6655,
        0.6885,
        0.6776,
        0.7086,
        0.7305,
        0.7098,
        0.6787,
        0.6983,
        0.704,
        0.6908,
        0.7195,
        0.723,
        0.7029,
        0.727,
        0.7121,
        0.7408,
        0.7351,
        0.7523,
        0.7621,
        0.7397,
        0.7489,
        0.7425,
        0.7408,
        0.7316,
        0.7425,
        0.7592,
        0.7253,
        0.7724,
        0.7667,
        0.7529,
        0.7362,
        0.7609,
        0.7828,
        0.7448,
        0.7563,
        0.7713,
        0.7747,
        0.7891,
        0.7632,
        0.7741,
        0.7575,
        0.7759,
        0.7736,
        0.7724,
        0.7632,
        0.7736,
        0.7994,
        0.7954,
        0.7816,
        0.7793,
        0.7851,
        0.7822,
        0.7724,
        0.792,
        0.7902,
        0.7897,
        0.7937,
        0.8017,
        0.7868
      ]
    }
  },
  "branched_self_attention": {
    "log_file": "emotion_training_logs/training_branched_self_attention.log",
    "summary": {
      "epochs_completed": 47,
      "latest_val_accuracy": 0.8285,
      "best_val_accuracy": 0.8335,
      "best_epoch": 37,
      "recent_trend": -0.001649999999999942
    },
    "metrics": {
      "epoch": [
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12,
        13,
        14,
        15,
        16,
        17,
        18,
        19,
        20,
        21,
        22,
        23,
        24,
        25,
        26,
        27,
        28,
        29,
        30,
        31,
        32,
        33,
        34,
        35,
        36,
        37,
        38,
        39,
        40,
        41,
        42,
        43,
        44,
        45,
        46,
        47
      ],
      "val_accuracy": [
        0.3571,
        0.4016,
        0.4511,
        0.4978,
        0.5202,
        0.5512,
        0.5534,
        0.6327,
        0.6265,
        0.6502,
        0.6569,
        0.689,
        0.7064,
        0.694,
        0.7452,
        0.7373,
        0.73,
        0.7441,
        0.761,
        0.7559,
        0.7486,
        0.7711,
        0.7733,
        0.7604,
        0.7705,
        0.77,
        0.7677,
        0.8015,
        0.8105,
        0.8127,
        0.8166,
        0.8048,
        0.8116,
        0.8116,
        0.8217,
        0.8268,
        0.8335,
        0.8206,
        0.8279,
        0.8313,
        0.8296,
        0.824,
        0.8335,
        0.833,
        0.8318,
        0.8268,
        0.8285
      ]
    }
  }
}