#!/bin/bash

# This script provides instructions for manually uploading the RAVDESS and CREMA-D 
# datasets to the EC2 instance

echo "=== MANUAL DATASET UPLOAD INSTRUCTIONS ==="
echo ""
echo "Since the automated downloads from Zenodo did not work, here are instructions"
echo "to manually upload the datasets to the EC2 instance:"
echo ""
echo "Option 1: If you have the datasets locally on your machine:"
echo "-------------------------------------------------------------"
echo "1. Download the datasets locally if you don't already have them:"
echo "   - RAVDESS: https://zenodo.org/record/1188976/files/Video_Speech_Actor_01-24.zip"
echo "   - CREMA-D: https://zenodo.org/record/1225427/files/CREMA-D.zip"
echo ""
echo "2. Upload them to the EC2 instance using scp:"
echo ""
echo "   # For RAVDESS:"
echo "   scp -i ~/Downloads/gpu-key.pem ~/path/to/Video_Speech_Actor_01-24.zip ubuntu@54.162.134.77:/home/ubuntu/datasets/"
echo ""
echo "   # For CREMA-D:"
echo "   scp -i ~/Downloads/gpu-key.pem ~/path/to/CREMA-D.zip ubuntu@54.162.134.77:/home/ubuntu/datasets/"
echo ""
echo "3. SSH into the EC2 instance to extract the files:"
echo "   ssh -i ~/Downloads/gpu-key.pem ubuntu@54.162.134.77"
echo ""
echo "4. Extract the datasets on the EC2 instance:"
echo "   cd /home/ubuntu/datasets"
echo ""
echo "   # Extract RAVDESS:"
echo "   unzip -q Video_Speech_Actor_01-24.zip -d ravdess_tmp"
echo "   mv ravdess_tmp/Video_Speech_Actor_* ravdess_videos/"
echo "   for dir in ravdess_videos/Video_Speech_Actor_*; do"
echo "     if [ -d \"$dir\" ]; then"
echo "       new_name=\"\${dir/Video_Speech_/}\""
echo "       mv \"\$dir\" \"\$new_name\""
echo "     fi"
echo "   done"
echo "   rm -rf ravdess_tmp Video_Speech_Actor_01-24.zip"
echo ""
echo "   # Extract CREMA-D:"
echo "   unzip -q CREMA-D.zip -d crema_d_tmp"
echo "   find crema_d_tmp -type f \\( -name \"*.mp4\" -o -name \"*.flv\" \\) -exec mv {} crema_d_videos/ \\;"
echo "   rm -rf crema_d_tmp CREMA-D.zip"
echo ""
echo "Option 2: Direct download on EC2 with special parameters:"
echo "-------------------------------------------------------------"
echo "SSH into the EC2 instance and try downloading with different parameters:"
echo ""
echo "ssh -i ~/Downloads/gpu-key.pem ubuntu@54.162.134.77"
echo ""
echo "Once connected, run:"
echo "cd /home/ubuntu/datasets"
echo ""
echo "# Try downloading with better options for large files:"
echo "wget --no-check-certificate --content-disposition --retry-connrefused --timeout=30 \\"
echo "     --waitretry=1 --read-timeout=20 --tries=3 \\"
echo "     https://zenodo.org/record/1188976/files/Video_Speech_Actor_01-24.zip"
echo ""
echo "wget --no-check-certificate --content-disposition --retry-connrefused --timeout=30 \\"
echo "     --waitretry=1 --read-timeout=20 --tries=3 \\"
echo "     https://zenodo.org/record/1225427/files/CREMA-D.zip"
echo ""
echo "Then extract them as shown in Option 1 step 4."
echo ""
echo "Option 3: Use alternative sources:"
echo "-------------------------------------------------------------"
echo "If options 1 and 2 don't work, consider using alternative sources:"
echo ""
echo "1. Transfer from another cloud storage (S3, GCS, etc.)"
echo "2. Use academic mirrors if available"
echo "3. Consider using torrent if available with appropriate permissions"
echo ""
echo "After successful upload and extraction, confirm the path locations:"
echo "RAVDESS_VIDEOS_PATH=/home/ubuntu/datasets/ravdess_videos"
echo "CREMA_D_VIDEOS_PATH=/home/ubuntu/datasets/crema_d_videos"
echo ""
echo "Then run the FER feature extraction script:"
echo "cd /home/ubuntu/emotion-recognition"
echo "python scripts/extract_fer_features.py --dataset all"
