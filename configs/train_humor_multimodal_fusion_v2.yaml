# Configuration for HumorFusionModelV2 Training

model_params:
  audio_input_dim: 1024      # WavLM-Base+ output dimension (sequential)
  text_input_dim: 1024       # XLM-RoBERTa-Large output dimension (pooled)
  video_au_input_dim: 17     # Number of OpenFace AU intensity columns
  audio_lstm_hidden_dim: 256
  video_au_lstm_hidden_dim: 128
  text_fc_dim: 512           # Intermediate FC layer for text features
  fusion_dim: 512            # Dimension of the concatenated features from each branch before final fusion layers
  num_classes: 2
  dropout_rate: 0.4

data_params:
  train_manifest_path: "datasets/manifests/humor/urfunny_multimodal_v2_final.csv" # Will be split by 'split' column
  val_manifest_path: "datasets/manifests/humor/urfunny_multimodal_v2_final.csv"   # Will be split by 'split' column
  test_manifest_path: "datasets/manifests/humor/urfunny_multimodal_v2_final.csv"  # Will be split by 'split' column
  
  # Max sequence lengths for padding/truncation. 
  # These should ideally be set based on dataset analysis (e.g., 95th percentile).
  # If None, the dataloader will use the raw sequence lengths (requires custom collate_fn for batching if lengths vary)
  # For simplicity with PyTorch Lightning's default collate, we'll set some values.
  # The Dataloader currently pads/truncates.
  max_audio_len: 600        # Example: ~10 seconds at 60fps for audio features (adjust based on actual features)
  max_video_au_len: 600     # Example: ~10 seconds at 60fps for video features

  num_workers: 4

training_params:
  learning_rate: 0.0001
  weight_decay: 0.001
  batch_size: 32
  epochs: 50 # Increased from previous 20
  
  # Class weights: [weight_for_class_0, weight_for_class_1]
  # Calculate based on class imbalance if needed. Example:
  # class_weights: [0.7, 1.3] # If class 0 is more frequent
  class_weights: null # Set to null or remove if not using, or provide actual weights e.g. [1.0, 1.0] for no weighting

  scheduler:
    type: "linear_with_warmup"
    warmup_ratio: 0.1 # Percentage of total steps for warmup

  early_stopping_patience: 10 # Increased from 5
  monitor_metric: "val_f1"    # Metric to monitor for checkpointing and early stopping
  monitor_mode: "max"         # 'max' for F1/Accuracy/AUROC, 'min' for Loss
  save_top_k: 2
  deterministic: False
  # use_amp: False # Set to true for mixed precision training
  f1_average: 'binary' # or 'macro' or 'weighted' for multiclass
